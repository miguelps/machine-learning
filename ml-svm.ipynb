{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "id": "VM3u54NNu4MC",
        "outputId": "8a2a8542-353d-4ae3-8baf-ac84471e6b1e"
      },
      "source": [
        "# M√°quinas de Vectores de Soporte (SVM)\n",
        "## Presentaci√≥n - Encuentro 4\n",
        "\n",
        "---\n",
        "\n",
        "## 1. ¬øQu√© es SVM?\n",
        "\n",
        "### Concepto Simple\n",
        "Las **M√°quinas de Vectores de Soporte (SVM)** son algoritmos que encuentran la **mejor manera de separar** diferentes grupos de datos.\n",
        "\n",
        "### Analog√≠a Visual\n",
        "Imagine que tiene **perros** y **gatos** mezclados en un patio. El SVM encuentra la **l√≠nea m√°s amplia** entre ellos para separarlos claramente.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Los 4 Conceptos Fundamentales\n",
        "\n",
        "### 2.1 Hiperplano\n",
        "- **Qu√© es**: La l√≠nea (o plano) que separa las clases\n",
        "- **Objetivo**: Buscar la l√≠nea que est√© lo m√°s lejos posible de ambos grupos\n",
        "- **Visualizaci√≥n**:\n",
        "  - 2D: una l√≠nea recta\n",
        "  - 3D: un plano\n",
        "  - nD: un hiperplano (generalizaci√≥n)\n",
        "\n",
        "    <img src=\"clasificador-c.jpg\" width=\"600\">\n",
        "\n",
        "    [Imagen extraida de Luis G. Serrano - Machine Learning]()\n",
        "\n",
        "### 2.2 Vectores de Soporte\n",
        "- **Qu√© son**: Los puntos de datos **m√°s cercanos** a la l√≠nea de separaci√≥n\n",
        "- **Importancia**: Solo necesitas estos puntos para clasificar nuevos datos\n",
        "- **Ventaja**: Muy eficiente en memoria\n",
        "\n",
        "  **Ejemplo**: 1000 muestras $\\to$ 50 vectores (puntos) de soporte\n",
        "\n",
        "### 2.3 Margen\n",
        "- **Qu√© es**: El espacio libre entre la l√≠nea de separaci√≥n y los puntos m√°s cercanos\n",
        "- **Objetivo**: Maximizar este espacio para crear una separaci√≥n m√°s robusta\n",
        "- **Tipos**:\n",
        "  - **Margen duro**: No permite errores\n",
        "  - **Margen suave**: Permite algunos errores (m√°s flexible)\n",
        "\n",
        "    <img src=\"clasificador-a.jpg\" width=\"600\">\n",
        "\n",
        "    [Imagen extraida de Luis G. Serrano - Machine Learning]()\n",
        "\n",
        "### 2.4 Kernel\n",
        "- **Qu√© es**: Una funci√≥n que permite separaciones **no lineales** (curvas)\n",
        "- **Tipos principales**:\n",
        "  - **Lineal**: Separaciones rectas (m√°s r√°pido)\n",
        "  - **RBF**: Separaciones curvas complejas (m√°s flexible)\n",
        "  - **Polinomial**: Separaciones con curvas polin√≥micas\n",
        "- **Cu√°ndo usar**: RBF para casos generales\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Par√°metros Principales\n",
        "\n",
        "### Par√°metro C (Regularizaci√≥n)\n",
        "| Valor             | Significado                            | Uso Recomendado               |\n",
        "|-------------------|----------------------------------------|-------------------------------|\n",
        "| C grande (>100)   | L√≠nea r√≠gida, pocos errores permitidos | Cuando quieres alta precisi√≥n |\n",
        "| C peque√±o (<1)    | L√≠nea flexible, m√°s errores permitidos | Cuando los datos tienen ruido |\n",
        "| **Valor inicial** | C=1                                    | Punto de partida est√°ndar     |\n",
        "\n",
        "### Par√°metro gamma (Solo para kernel RBF)\n",
        "| Valor                | Significado          | Uso Recomendado         |\n",
        "|----------------------|----------------------|-------------------------|\n",
        "| gamma grande (>1)    | Curvas muy complejas | Riesgo de sobreajuste   |\n",
        "| gamma peque√±o (<0.1) | Curvas suaves        | Mejor generalizaci√≥n    |\n",
        "| **Valor inicial**    | gamma=0.1            | Valor seguro y est√°ndar |\n",
        "\n",
        "### Grid Search\n",
        "- **Qu√© es**: Prueba autom√°ticamente diferentes combinaciones de par√°metros\n",
        "- **Ventaja**: Encuentra la mejor combinaci√≥n autom√°ticamente\n",
        "- **Resultado**: Te entrega el modelo ya optimizado\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Flujo de Trabajo con SVM\n",
        "\n",
        "### Paso a Paso\n",
        "\n",
        "1. **Preparar datos**\n",
        "   - **CR√çTICO**: Normalizar con StandardScaler\n",
        "   - SVM es muy sensible a la escala de los datos\n",
        "\n",
        "2. **Dividir datos**\n",
        "   - 80% para entrenamiento\n",
        "   - 20% para prueba\n",
        "\n",
        "3. **Grid Search**\n",
        "   - Prueba diferentes combinaciones autom√°ticamente\n",
        "   - Ya entrena el modelo con los mejores par√°metros\n",
        "\n",
        "4. **Evaluar y visualizar**\n",
        "   - Ver las fronteras de decisi√≥n\n",
        "   - Calcular m√©tricas de rendimiento\n",
        "\n",
        "### Ejemplo: Comparaci√≥n de SVM con GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SVM (lineal, RBF y polinomial), GridSearchCV, 5-Fold y PCA para visualizaci√≥n\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay, classification_report\n",
        "from sklearn.decomposition import PCA\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 1. Generar datos sint√©ticos (puedes cambiar n_features > 2 para probar PCA)\n",
        "X, y = make_blobs(n_samples=400, centers=2, n_features=5, cluster_std=4, random_state=42)\n",
        "\n",
        "# 2. Dividir en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# 3. Definir la grilla de hiperpar√°metros\n",
        "param_grid = [\n",
        "    {'kernel': ['linear'], 'C': [0.1, 1, 10]},\n",
        "    {'kernel': ['rbf'], 'C': [0.1, 1, 10], 'gamma': ['scale', 0.1, 1]},\n",
        "    {'kernel': ['poly'], 'C': [0.1, 1, 10], 'degree': [2, 3, 4], 'gamma': ['scale', 0.1, 1]}\n",
        "]\n",
        "\n",
        "# 4. Crear el modelo base y el GridSearchCV con validaci√≥n cruzada (5 folds)\n",
        "svm = SVC()\n",
        "grid = GridSearchCV(estimator=svm, param_grid=param_grid, cv=5, n_jobs=-1, verbose=1)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# 5. Mostrar los mejores par√°metros\n",
        "print(\"üß† Mejor combinaci√≥n encontrada por GridSearchCV:\")\n",
        "print(grid.best_params_)\n",
        "print(f\"Mejor puntuaci√≥n media de validaci√≥n: {grid.best_score_:.3f}\")\n",
        "\n",
        "# 6. Evaluar el mejor modelo\n",
        "best_svm = grid.best_estimator_\n",
        "y_pred = best_svm.predict(X_test)\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nüéØ Precisi√≥n en el conjunto de prueba: {acc:.3f}\")\n",
        "print(\"\\nüìä Reporte de clasificaci√≥n:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# 7. Matriz de confusi√≥n\n",
        "ConfusionMatrixDisplay.from_estimator(best_svm, X_test, y_test, cmap='Blues')\n",
        "plt.title(\"Matriz de confusi√≥n del mejor SVM\")\n",
        "plt.show()\n",
        "\n",
        "# 8. Reducci√≥n a 2D con PCA (solo para visualizaci√≥n)\n",
        "if X.shape[1] > 2:\n",
        "    print(f\"\\nüìâ Aplicando PCA: reducci√≥n de {X.shape[1]} ‚Üí 2 dimensiones para visualizaci√≥n.\")\n",
        "    pca = PCA(n_components=2)\n",
        "    X_vis = pca.fit_transform(X)\n",
        "else:\n",
        "    X_vis = X  # si ya tiene 2 dimensiones, no aplicamos PCA\n",
        "\n",
        "# 9. Visualizaci√≥n de fronteras de decisi√≥n\n",
        "# ‚ö†Ô∏è Usamos PCA solo para graficar, no para entrenar el modelo (por claridad)\n",
        "# En escenarios reales, puedes aplicar PCA antes del entrenamiento si lo deseas.\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "\n",
        "# Crear una malla 2D\n",
        "x_min, x_max = X_vis[:, 0].min() - 1, X_vis[:, 0].max() + 1\n",
        "y_min, y_max = X_vis[:, 1].min() - 1, X_vis[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 300),\n",
        "                     np.linspace(y_min, y_max, 300))\n",
        "\n",
        "# Si los datos fueron reducidos con PCA, proyectamos la malla al espacio original para predecir\n",
        "if X.shape[1] > 2:\n",
        "    # Invertimos la proyecci√≥n para estimar el espacio original\n",
        "    grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
        "    grid_points_original = pca.inverse_transform(grid_points)\n",
        "    Z = best_svm.predict(grid_points_original)\n",
        "else:\n",
        "    Z = best_svm.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "# Dibujar fronteras\n",
        "plt.contourf(xx, yy, Z, alpha=0.3, cmap='Accent')\n",
        "plt.scatter(X_vis[:, 0], X_vis[:, 1], c=y, cmap='Accent', edgecolors='k')\n",
        "plt.title(f\"Fronteras de decisi√≥n del mejor SVM ({grid.best_params_['kernel']})\")\n",
        "plt.xlabel(\"Componente 1 (PCA)\" if X.shape[1] > 2 else \"Caracter√≠stica 1\")\n",
        "plt.ylabel(\"Componente 2 (PCA)\" if X.shape[1] > 2 else \"Caracter√≠stica 2\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. ¬øCu√°ndo Usar SVM?\n",
        "\n",
        "### ‚úÖ Ventajas\n",
        "- **Eficiente en memoria**: Solo almacena vectores de soporte\n",
        "- **Bueno con alta dimensionalidad**: Funciona bien con muchas caracter√≠sticas\n",
        "- **Flexible**: Diferentes kernels para diferentes tipos de separaci√≥n\n",
        "- **Robusto**: Resiste datos at√≠picos\n",
        "\n",
        "### ‚ö†Ô∏è Desventajas\n",
        "- **Lento con datasets muy grandes** (>10,000 muestras)\n",
        "- **Requiere normalizaci√≥n** (no opcional)\n",
        "- **Par√°metros sensibles** (requieren ajuste)\n",
        "\n",
        "### üéØ Cu√°ndo Usar\n",
        "- Dataset peque√±o a mediano (<10,000 muestras)\n",
        "- Necesitas separaciones no lineales\n",
        "- Trabajas con alta dimensionalidad\n",
        "- Necesitas un modelo robusto\n",
        "\n",
        "---\n",
        "\n",
        "## 6. M√©tricas de Evaluaci√≥n\n",
        "\n",
        "### Matriz de Confusi√≥n\n",
        "\n",
        "| Real \\ Predicci√≥n | Positiva        | Negativa        |\n",
        "|-------------------|-----------------|-----------------|\n",
        "| **Positiva**      | **VP** o **TP** | FN              |\n",
        "| **Negativa**      | FP              | **VN** o **TN** |\n",
        "\n",
        "#### Ejemplo:\n",
        "\n",
        "| Real \\ Predicho | Perro       | Gato        | P√°jaro      |\n",
        "|-----------------|-------------|-------------|-------------|\n",
        "| **Perro**       | **70 (TP)** | 5 (FN)      | 2 (FN)      |\n",
        "| **Gato**        | 10 (FP)     | **85 (TP)** | 5           |\n",
        "| **P√°jaro**      | 0 (FP)      | 3           | **95 (TP)** |\n",
        "\n",
        "\n",
        "### M√©tricas Principales\n",
        "\n",
        "**F√≥rmulas b√°sicas:**\n",
        "- **Accuracy**: (TP + TN) / Total\n",
        "- **Precision**: TP / (TP + FP)  \n",
        "- **Recall**: TP / (TP + FN)\n",
        "- **F1-Score**: 2 √ó (Precision √ó Recall) / (Precision + Recall)\n",
        "\n",
        "| M√©trica       | Interpretaci√≥n                                |\n",
        "|---------------|-----------------------------------------------|\n",
        "| **Accuracy**  | Porcentaje de clasificaciones correctas      |\n",
        "| **Precision** | De los predichos positivos, ¬øcu√°ntos son realmente positivos? |\n",
        "| **Recall**    | De los realmente positivos, ¬øcu√°ntos detectamos? |\n",
        "| **F1-Score**  | Balancea precisi√≥n y recall (media arm√≥nica)  |\n",
        "\n",
        "### ¬øQu√© M√©trica Usar?\n",
        "\n",
        "| Escenario                    | M√©trica Principal | Raz√≥n                           |\n",
        "|------------------------------|-------------------|---------------------------------|\n",
        "| Clases balanceadas           | **Accuracy**      | Representa bien el rendimiento  |\n",
        "| Clase minoritaria importante | **F1-Score**      | Balancea ambas m√©tricas         |\n",
        "| Evitar falsas alarmas        | **Precision**     | Ej: spam vs no-spam             |\n",
        "| Detectar todos los casos     | **Recall**        | Ej: detecci√≥n de fallas, c√°ncer |\n",
        "| Clases desbalanceadas        | **Macro F1**      | No se sesga por mayor√≠a         |\n",
        "\n",
        "---\n",
        "\n",
        "## 7. Mejores Pr√°cticas\n",
        "\n",
        "### ‚úÖ Hacer SIEMPRE\n",
        "1. **Normalizar datos** (cr√≠tico)\n",
        "2. Usar **Grid Search** para encontrar mejores par√°metros\n",
        "3. **Validaci√≥n cruzada** para evaluar robustez\n",
        "4. Comparar **train vs test accuracy** para detectar sobreajuste\n",
        "5. Empezar con valores conservadores de C y gamma\n",
        "\n",
        "### ‚ùå Errores Comunes\n",
        "1. **No normalizar** datos de prueba correctamente\n",
        "2. **Usar datos de prueba durante entrenamiento**\n",
        "3. **Ignorar sobreajuste** (train accuracy alta, test baja)\n",
        "4. **Valores extremos** de C y gamma sin validar\n",
        "5. **No visualizar** las fronteras de decisi√≥n\n",
        "\n",
        "### üéØ Interpretaci√≥n de Resultados\n",
        "- **Pocos vectores de soporte**: Modelo simple y generalizable ‚úÖ\n",
        "- **Muchos vectores de soporte**: Modelo complejo (posible sobreajuste) ‚ö†Ô∏è\n",
        "- **Train accuracy alta, test baja**: Sobreajuste (reducir C o gamma)\n",
        "- **Baja accuracy en ambos**: Bajo rendimiento (cambiar kernel o par√°metros)\n",
        "\n",
        "---\n",
        "\n",
        "## 8. El Camino de los Datos: Entrenamiento ‚Üí Predicci√≥n\n",
        "\n",
        "  <img src=\"ml-svm-blocos_diagram_01.png\" width=\"500\">\n",
        "\n",
        "---\n",
        "\n",
        "## 9. Entrenamiento del modelo\n",
        "\n",
        "  <img src=\"ml-svm-blocos_diagram_02.png\" width=\"700\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Puntos Clave para Recordar\n",
        "\n",
        "### üéØ Los 3 Conceptos Esenciales\n",
        "1. **Hiperplano**: La l√≠nea que separa clases\n",
        "2. **Vectores de Soporte**: Puntos clave que definen la separaci√≥n\n",
        "3. **Margen**: Espacio que queremos maximizar\n",
        "\n",
        "### üîß Los 2 Par√°metros Cr√≠ticos\n",
        "1. **C**: Controla cu√°nto errores permitir (C grande = menos errores)\n",
        "2. **gamma**: Controla complejidad de curvas (gamma peque√±o = m√°s simple)\n",
        "\n",
        "### ‚úÖ El Flujo Clave\n",
        "1. Normalizar ‚ö†Ô∏è (SIEMPRE)\n",
        "2. Grid Search (optimizaci√≥n autom√°tica)\n",
        "3. Visualizar (entender el modelo)\n",
        "4. Evaluar (m√©tricas adecuadas)\n",
        "\n",
        "---\n",
        "\n",
        "## 11. Pr√≥ximos Pasos\n",
        "\n",
        "### Para Practicar\n",
        "1. ‚úÖ Ejecutar el notebook de pr√°ctica\n",
        "2. ‚úÖ Probar diferentes kernels (lineal, RBF)\n",
        "3. ‚úÖ Cambiar par√°metros C y gamma\n",
        "4. ‚úÖ Aplicar a dataset real (ej: Iris)\n",
        "5. ‚úÖ Experimentar con datos multiclase\n",
        "\n",
        "### Para Profundizar\n",
        "- Explorar SVM multiclase\n",
        "- Implementar en casos industriales reales\n",
        "- Comparar con otros algoritmos (Random Forest, Redes Neuronales)\n",
        "- Estudiar teor√≠a matem√°tica de SVM\n",
        "\n",
        "---\n",
        "\n",
        "## 12. Recursos y Referencias\n",
        "\n",
        "### Documentaci√≥n\n",
        "- Grokking Machine Learning, Luis G. Serrano, 2021\n",
        "- [Scikit-learn: SVM](https://scikit-learn.org/stable/modules/svm.html)\n",
        "- [Grid Search Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
        "\n",
        "### Para Aprender M√°s\n",
        "- Libro: \"Pattern Recognition and Machine Learning\" - Christopher Bishop\n",
        "- Curso: Machine Learning por Andrew Ng (Coursera)\n",
        "\n",
        "---\n",
        "\n",
        "## ¬øPreguntas?\n",
        "\n",
        "*Tiempo restante para preguntas y discusi√≥n*\n",
        "\n",
        "---\n",
        "\n",
        "## Ap√©ndice: Comparaci√≥n R√°pida con Otros Algoritmos\n",
        "\n",
        "| Algoritmo           | Interpretabilidad | Escalabilidad | Datos No Lineales | Velocidad |\n",
        "|---------------------|-------------------|---------------|-------------------|-----------|\n",
        "| **SVM**             | Media             | Baja          | Excelente         | Media     |\n",
        "| Random Forest       | Alta              | Alta          | Buena             | Alta      |\n",
        "| Redes Neuronales    | Baja              | Media         | Excelente         | Media     |\n",
        "| Regresi√≥n Log√≠stica | Alta              | Alta          | Limitada          | Alta      |\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
