{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWr76VevFL6_"
      },
      "source": [
        "<!-- # Regresión y Selección de Modelos\n",
        "\n",
        "## Aplicaciones en Ingeniería Electrónica\n",
        "\n",
        "Este notebook contiene ejemplos prácticos y aplicaciones de regresión y selección de modelos en el contexto de ingeniería electrónica.\n",
        "\n",
        "<a id=\"contenido\"></a>\n",
        "\n",
        "### Temas Cubiertos:\n",
        "\n",
        "[**Ejemplos de Aplicaciones Prácticas**](#x)\n",
        "\n",
        "1. [**Calibración de Sensores**](#calibracion-sensores)\n",
        "2. [**Predicción de Fallas en Circuitos**](#prediccion-fallas)\n",
        "3. [**Optimización de Parámetros de Fabricación**](#optimizacion-parametros)\n",
        "4. [**Selección de Modelos y Validación Cruzada**](#seleccion-modelos)\n",
        "5. [**Control de Procesos Industriales**](#control-procesos)\n",
        "\n",
        "[**Resumen y Conclusiones**](#resumen) -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJ_eJFf_FL7C"
      },
      "source": [
        "<a id=\"contenido\"></a>\n",
        "\n",
        "\n",
        "# Regresión y Selección de Modelos en Machine Learning\n",
        "\n",
        "\n",
        "## Aplicaciones Prácticas\n",
        "\n",
        "1. **[Calibración de Sensores de Temperatura](#calibracion-sensores)**\n",
        "2. **[Optimización de Parámetros de Fabricación de Resistencias](#optimizacion-parametros)**\n",
        "3. **[Selección de Modelos y Validación Cruzada](#seleccion-modelos)**\n",
        "\n",
        "---\n",
        "\n",
        "### Objetivos de Aprendizaje\n",
        "\n",
        "- Aplicar modelos de regresión lineal a problemas reales de ingeniería\n",
        "- Comparar diferentes algoritmos: Linear, Ridge, Lasso, Random Forest\n",
        "- Implementar técnicas de validación cruzada y optimización de hiperparámetros\n",
        "- Evaluar modelos usando métricas apropiadas (RMSE, R², MAE)\n",
        "- Interpretar resultados y seleccionar el mejor modelo\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETPkULRZFL7E"
      },
      "source": [
        "### Importar librerías necesarias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8FY-ipBFL7F"
      },
      "outputs": [],
      "source": [
        "# Importar librerías necesarias\n",
        "import numpy as np               # Operaciones numéricas y arrays\n",
        "import pandas as pd              # Manipulación de datos tabulares\n",
        "import matplotlib.pyplot as plt  # Visualización de datos\n",
        "import seaborn as sns            # Visualización estadística avanzada\n",
        "\n",
        "# Modelos de Machine Learning\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LogisticRegression\n",
        "# StandardScaler: Estandarización, PolynomialFeatures: Crear términos polinomiales\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "# train_test_split: Dividir datos, cross_val_score: Validación cruzada, GridSearchCV: Optimización\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "# Métricas para evaluación de modelos\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, classification_report, confusion_matrix\n",
        "# Modelos de ensemble (combinación de múltiples modelos)\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "\n",
        "# Suprimir advertencias para visualización limpia\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configurar estilo de gráficos\n",
        "plt.style.use('seaborn-v0_8')   # Estilo visual moderno\n",
        "sns.set_palette(\"husl\")         # Paleta de colores armoniosa\n",
        "\n",
        "print(\"Librerías importadas correctamente\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yl9ALXPFL7H"
      },
      "source": [
        "<a id=\"calibracion-sensores\"></a>\n",
        "\n",
        "## 1. Calibración de Sensores de Temperatura [⬆](#contenido)\n",
        "\n",
        "### Problema:\n",
        "Un sensor de temperatura tiene desgaste y no linealidad. Necesitamos crear un modelo de calibración que convierta la lectura del sensor (voltaje) a temperatura real.\n",
        "\n",
        "### Datos:\n",
        "- Temperatura real (°C): 5, 25, 50, 75, 100\n",
        "- Lectura del sensor (V): 0.1, 1.2, 2.4, 3.6, 4.8\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlhV4aj4FL7J"
      },
      "outputs": [],
      "source": [
        "# Crear datos de calibración del sensor\n",
        "\n",
        "# Puntos de referencia conocidos (medidos con termómetro de precisión)\n",
        "temperatura_real = np.array([5, 25, 50, 75, 100])     # °C, temperatura real medida\n",
        "lectura_sensor = np.array([0.1, 1.2, 2.4, 3.6, 4.8])  #  V, voltaje de salida del sensor\n",
        "\n",
        "# Crear DataFrame para organizar los datos de manera tabular\n",
        "df_sensor = pd.DataFrame({\n",
        "    'lectura_sensor': lectura_sensor,\n",
        "    'temperatura_real': temperatura_real,\n",
        "})\n",
        "\n",
        "print(\"Datos del sensor:\")\n",
        "print(df_sensor)\n",
        "\n",
        "# Visualizar la relación\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(lectura_sensor, temperatura_real, s=100, alpha=0.7, color='blue')\n",
        "plt.xlabel('Lectura del Sensor (V)')\n",
        "plt.ylabel('Temperatura Real (°C)')\n",
        "plt.title('Calibración de Sensor de Temperatura')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_NdgHlHaFL7K"
      },
      "outputs": [],
      "source": [
        "# Ajustar modelo de regresión lineal\n",
        "\n",
        "# Reshape(-1, 1): Convierte el array 1D en matriz columna (necesario para sklearn)\n",
        "X_sensor = lectura_sensor.reshape(-1, 1)\n",
        "y_sensor = temperatura_real\n",
        "\n",
        "# Modelo lineal simple\n",
        "modelo_lineal = LinearRegression()\n",
        "# fit(): Entrena el modelo encontrando los coeficientes que minimizan el error cuadrático\n",
        "modelo_lineal.fit(X_sensor, y_sensor)\n",
        "\n",
        "# Predecir temperaturas\n",
        "# predict(): Aplica la ecuación T = intercept + coef * V a los datos de entrada\n",
        "y_pred_lineal = modelo_lineal.predict(X_sensor)\n",
        "\n",
        "# Calcular métricas\n",
        "\n",
        "# MSE: Error cuadrático medio, penaliza errores grandes\n",
        "mse_lineal = mean_squared_error(y_sensor, y_pred_lineal)\n",
        "\n",
        "# RMSE: Raíz del MSE, en las mismas unidades que la variable objetivo\n",
        "rmse_lineal = np.sqrt(mse_lineal)\n",
        "\n",
        "# R²: Coeficiente de determinación, mide qué tan bien el modelo explica la variabilidad (0-1)\n",
        "r2_lineal = r2_score(y_sensor, y_pred_lineal)\n",
        "\n",
        "print(f\"Modelo Lineal:\")\n",
        "print(f\"Ecuación: T = {modelo_lineal.intercept_:.2f} + {modelo_lineal.coef_[0]:.2f} * V\")\n",
        "print(f\"RMSE: {rmse_lineal:.2f} °C\")\n",
        "print(f\"R²: {r2_lineal:.4f}\")\n",
        "\n",
        "# Visualizar resultados\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Subgráfico 1: Ajuste del modelo\n",
        "plt.subplot(1, 2, 1)\n",
        "\n",
        "plt.scatter(lectura_sensor, temperatura_real, s=100, alpha=0.7, color='blue', label='Datos reales')\n",
        "    # s: tamaño de puntos, alpha: transparencia\n",
        "\n",
        "# Línea de regresión (predicciones del modelo)\n",
        "plt.plot(lectura_sensor, y_pred_lineal, 'r-', linewidth=2, label='Modelo lineal')\n",
        "\n",
        "plt.xlabel('Lectura del Sensor (V)')\n",
        "plt.ylabel('Temperatura Real (°C)')\n",
        "plt.title('Calibración Lineal')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Subgráfico 2: Análisis de residuos\n",
        "plt.subplot(1, 2, 2)\n",
        "\n",
        "# Residuos: Diferencia entre valor real y predicción (e_i = y_i - ŷ_i)\n",
        "residuos = temperatura_real - y_pred_lineal\n",
        "plt.scatter(y_pred_lineal, residuos, s=100, alpha=0.7, color='green')\n",
        "\n",
        "# Línea horizontal en y=0 (residuos ideales deben estar alrededor de 0)\n",
        "plt.axhline(y=0, color='r', linestyle='--')\n",
        "\n",
        "plt.xlabel('Temperatura Predicha (°C)')\n",
        "plt.ylabel('Residuos (°C)')\n",
        "plt.title('Análisis de Residuos')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuVRgXCTFL7L"
      },
      "source": [
        "<a id=\"optimizacion-parametros\"></a>\n",
        "\n",
        "## 2. Optimización de Parámetros de Fabricación de Resistencias [⬆](#contenido)\n",
        "\n",
        "### Problema:\n",
        "Optimizar los parámetros de fabricación para obtener resistencias con valores específicos.\n",
        "\n",
        "### Variables:\n",
        "- **Temperatura de cocción** (°C)\n",
        "- **Tiempo de cocción** (minutos)\n",
        "- **Espesor del material** (μm)\n",
        "- **Concentración de dopante** (%)\n",
        "- **Objetivo**: Resistencia (Ω)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xSh2En9FL7M"
      },
      "outputs": [],
      "source": [
        "# Generar datos de fabricación de resistencias\n",
        "\n",
        "np.random.seed(127)\n",
        "n_resistencias = 150\n",
        "\n",
        "# Parámetros de fabricación\n",
        "\n",
        "# uniform(min, max, n): Distribución uniforme (todos los valores igualmente probables)\n",
        "temp_coccion = np.random.uniform(800, 1200, n_resistencias)          # °C, rango de cocción típico\n",
        "tiempo_coccion = np.random.uniform(30, 120, n_resistencias)          # min\n",
        "espesor = np.random.uniform(10, 50, n_resistencias)                  # μm, espesor de película\n",
        "concentracion_dopante = np.random.uniform(0.1, 5.0, n_resistencias)  # %, dopaje del material\n",
        "\n",
        "# Modelo físico simplificado para resistencia\n",
        "# Basado en ley de Ohm: R = ρ * L / A, donde ρ depende de temperatura y dopante\n",
        "# exp(): Función exponencial, modela efecto no lineal de temperatura\n",
        "resistividad_base = 0.1                             # Ω·μm, resistividad base del material\n",
        "factor_temp = np.exp(-(temp_coccion - 1000) / 200)  # Efecto de temperatura (Arrhenius)\n",
        "factor_dopante = 1 / (1 + concentracion_dopante)    # Dopante reduce resistencia\n",
        "factor_espesor = 1 / espesor                        # Menor espesor = mayor resistencia\n",
        "\n",
        "# Calcular resistencia con modelo físico más ruido gaussiano (simula imperfecciones)\n",
        "resistencia = (resistividad_base * factor_temp * factor_dopante * factor_espesor *\n",
        "               (1 + 0.1 * np.random.normal(0, 1, n_resistencias)))  # 10% de ruido\n",
        "\n",
        "# Crear DataFrame\n",
        "df_resistencias = pd.DataFrame({\n",
        "    'temp_coccion':          temp_coccion,\n",
        "    'tiempo_coccion':        tiempo_coccion,\n",
        "    'espesor':               espesor,\n",
        "    'concentracion_dopante': concentracion_dopante,\n",
        "    'resistencia':           resistencia\n",
        "})\n",
        "\n",
        "print(\"Datos de fabricación de resistencias:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"\\nMuestras:\")\n",
        "df_resistencias.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"\\nEstadísticas descriptivas:\")\n",
        "df_resistencias.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJ3A9xzkFL7O"
      },
      "outputs": [],
      "source": [
        "# Análisis exploratorio de datos de resistencias\n",
        "\n",
        "plt.figure(figsize=(15, 12))\n",
        "\n",
        "# Relaciones entre variables independientes y la variable objetivo (resistencia)\n",
        "variables = ['temp_coccion', 'tiempo_coccion', 'espesor', 'concentracion_dopante']\n",
        "for i, var in enumerate(variables):\n",
        "    plt.subplot(2, 2, i+1)  # Grid 2x2 para visualizar todas las variables\n",
        "\n",
        "    # Gráfico de dispersión para identificar relaciones lineales o no lineales\n",
        "    plt.scatter(df_resistencias[var], df_resistencias['resistencia'], alpha=0.6)\n",
        "\n",
        "    plt.xlabel(var)\n",
        "    plt.ylabel('Resistencia (Ω)')\n",
        "    plt.title(f'Resistencia vs {var}')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "# Matriz de correlación: Identificar multicolinealidad entre variables\n",
        "correlation_matrix = df_resistencias.corr()\n",
        "    # Valores cercanos a 1/-1: Fuerte correlación positiva/negativa\n",
        "    # Valores cercanos a 0: No hay correlación lineal\n",
        "\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,\n",
        "            square=True, fmt='.2f')\n",
        "plt.title('Matriz de Correlación - Resistencias')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oaLAV75oFL7P"
      },
      "outputs": [],
      "source": [
        "# Entrenar y comparar diferentes modelos de regresión\n",
        "\n",
        "# Separar variables predictoras (X) y variable objetivo (y)\n",
        "X_resistencias = df_resistencias[['temp_coccion', 'tiempo_coccion', 'espesor', 'concentracion_dopante']]\n",
        "y_resistencias = df_resistencias['resistencia']\n",
        "\n",
        "# Dividir datos: 70% entrenamiento, 30% prueba\n",
        "# test_size=0.3: 30% para test, random_state: Reproducibilidad\n",
        "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(X_resistencias, y_resistencias,\n",
        "                                                           test_size=0.3, random_state=42)\n",
        "\n",
        "# Estandarizar: Transformar datos a media=0 y desviación=1\n",
        "# Crítico para Ridge, Lasso y otros modelos sensibles a la escala\n",
        "scaler_r = StandardScaler()\n",
        "X_train_r_scaled = scaler_r.fit_transform(X_train_r)    # Ajustar y transformar train\n",
        "X_test_r_scaled = scaler_r.transform(X_test_r)          # Solo transformar test (no ajustar)\n",
        "\n",
        "# Modelos a comparar\n",
        "modelos = {\n",
        "    'Regresión Lineal': LinearRegression(),             # Regresión sin regularización\n",
        "    'Ridge (α=0.1)':    Ridge(alpha=0.1),               # Regularización L2 leve (penaliza coef. grandes)\n",
        "    'Ridge (α=1.0)':    Ridge(alpha=1.0),               # Regularización L2 moderada\n",
        "    'Lasso (α=0.01)':   Lasso(alpha=0.01),              # Regularización L1 leve (puede hacer coef. = 0)\n",
        "    'Lasso (α=0.1)':    Lasso(alpha=0.1),               # Regularización L1 moderada\n",
        "    'Random Forest':    RandomForestRegressor(n_estimators=100, random_state=42)  # Ensemble de 100 árboles\n",
        "}\n",
        "\n",
        "resultados = {}\n",
        "\n",
        "print(\"Comparación de Modelos de Regresión:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "for nombre_modelo, modelo in modelos.items():\n",
        "    # Entrenar modelo según su tipo\n",
        "    if nombre_modelo == 'Random Forest':\n",
        "        # Random Forest: No necesita estandarización (basado en árboles)\n",
        "        modelo.fit(X_train_r, y_train_r)\n",
        "        y_pred = modelo.predict(X_test_r)\n",
        "    else:\n",
        "        # Modelos lineales: Requieren datos estandarizados para convergencia óptima\n",
        "        modelo.fit(X_train_r_scaled, y_train_r)\n",
        "        y_pred = modelo.predict(X_test_r_scaled)\n",
        "\n",
        "    # Calcular métricas de regresión\n",
        "    mse = mean_squared_error(y_test_r, y_pred)   # Error cuadrático medio\n",
        "    rmse = np.sqrt(mse)                          # Raíz del MSE (mismas unidades que objetivo)\n",
        "    mae = mean_absolute_error(y_test_r, y_pred)  # Error absoluto medio (robusto a outliers)\n",
        "    r2 = r2_score(y_test_r, y_pred)              # R² (proporción de varianza explicada, 0-1)\n",
        "\n",
        "    resultados[nombre_modelo] = {'RMSE': rmse, 'MAE': mae, 'R²': r2}\n",
        "    # print(f\"{nombre_modelo:20} | RMSE: {rmse:.4f} | MAE: {mae:.4f} | R²: {r2: .4f} |\")\n",
        "\n",
        "# Crear DataFrame de resultados\n",
        "df_resultados = pd.DataFrame(resultados).T\n",
        "print(df_resultados.round(4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KfSmBe2tFL7Q"
      },
      "outputs": [],
      "source": [
        "# Visualizar comparación de modelos\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Gráfico de barras para RMSE (menor es mejor)\n",
        "plt.subplot(1, 3, 1)\n",
        "df_resultados['RMSE'].plot(kind='bar', color='skyblue')\n",
        "plt.title('Comparación de RMSE')\n",
        "plt.ylabel('RMSE')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Gráfico de barras para R² (más cercano a 1 es mejor)\n",
        "plt.subplot(1, 3, 2)\n",
        "df_resultados['R²'].plot(kind='bar', color='lightgreen')\n",
        "plt.title('Comparación de R²')\n",
        "plt.ylabel('R²')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Gráfico de dispersión: Predicho vs Real (mejor modelo)\n",
        "# idxmax(): Retorna el índice del valor máximo (mejor R²)\n",
        "mejor_modelo = df_resultados['R²'].idxmax()\n",
        "# Reentrenar el mejor modelo para generar predicciones\n",
        "if mejor_modelo == 'Random Forest':\n",
        "    modelo_mejor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "    modelo_mejor.fit(X_train_r, y_train_r)\n",
        "    y_pred_mejor = modelo_mejor.predict(X_test_r)\n",
        "else:\n",
        "    modelo_mejor = Ridge(alpha=0.1)\n",
        "    modelo_mejor.fit(X_train_r_scaled, y_train_r)\n",
        "    y_pred_mejor = modelo_mejor.predict(X_test_r_scaled)\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.scatter(y_test_r, y_pred_mejor, alpha=0.6, color='red')\n",
        "# Línea diagonal perfecta (y=x): Si predicción = real, punto cae en esta línea\n",
        "plt.plot([y_test_r.min(), y_test_r.max()], [y_test_r.min(), y_test_r.max()], 'k--', lw=2)\n",
        "plt.xlabel('Resistencia Real (Ω)')\n",
        "plt.ylabel('Resistencia Predicha (Ω)')\n",
        "plt.title(f'Predicción vs Real - {mejor_modelo}')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nMejor modelo: {mejor_modelo}\")\n",
        "print(f\"R² = {df_resultados.loc[mejor_modelo, 'R²']:.4f}\")\n",
        "print(f\"RMSE = {df_resultados.loc[mejor_modelo, 'RMSE']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDnG2kp9FL7R"
      },
      "source": [
        "<a id=\"seleccion-modelos\"></a>\n",
        "\n",
        "## 3. Selección de Modelos y Validación Cruzada [⬆](#contenido)\n",
        "\n",
        "### Problema:\n",
        "Implementar técnicas de selección de modelos y validación cruzada para encontrar el mejor modelo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JmUsIJ8HFL7R"
      },
      "outputs": [],
      "source": [
        "# Validación cruzada para selección de hiperparámetros\n",
        "\n",
        "# Definir rangos de hiperparámetros para Ridge\n",
        "# alpha: Parámetro de regularización (valores más altos = más regularización)\n",
        "param_grid_ridge = {\n",
        "    'alpha': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\n",
        "}\n",
        "\n",
        "# Grid Search con validación cruzada\n",
        "# cv=5: Divide datos en 5 partes, entrena con 4 y valida con 1 (repite 5 veces)\n",
        "# scoring: Métrica a optimizar (negativo porque sklearn maximiza)\n",
        "ridge_cv = GridSearchCV(\n",
        "    Ridge(),                           # Modelo a optimizar\n",
        "    param_grid_ridge,                  # Grade de parámetros\n",
        "    cv=5,                              # 5-fold cross-validation\n",
        "    scoring='neg_mean_squared_error'   # Métrica a optimizar\n",
        ")\n",
        "\n",
        "# Prueba todas las combinaciones de hiperparámetros y selecciona la mejor\n",
        "ridge_cv.fit(X_train_r_scaled, y_train_r)\n",
        "\n",
        "print(\"Mejores parámetros para Ridge:\")\n",
        "\n",
        "# best_params_: Diccionario con los hiperparámetros óptimos encontrados\n",
        "print(ridge_cv.best_params_)\n",
        "\n",
        "# best_score_: Mejor score promedio obtenido en validación cruzada\n",
        "print(f\"Mejor score (negativo MSE): {ridge_cv.best_score_:.4f}\")\n",
        "\n",
        "# Comparar modelos con validación cruzada usando mejores hiperparámetros\n",
        "modelos_cv = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Ridge (CV)':        Ridge(alpha=ridge_cv.best_params_['alpha']),  # Usar alpha óptimo\n",
        "    'Lasso':             Lasso(alpha=0.01),\n",
        "    'Random Forest':     RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "}\n",
        "\n",
        "print(\"\\nValidación Cruzada (5-fold):\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "cv_scores = {}\n",
        "for nombre, modelo in modelos_cv.items():\n",
        "    # cross_val_score: Evalúa el modelo usando validación cruzada k-fold\n",
        "    # Divide datos en k partes, entrena k veces y promedia resultados\n",
        "    if nombre == 'Random Forest':\n",
        "        # Random Forest no requiere estandarización (invariante a escala)\n",
        "        scores = cross_val_score(modelo, X_train_r, y_train_r, cv=5, scoring='neg_mean_squared_error')\n",
        "    else:\n",
        "        # Modelos lineales requieren datos estandarizados\n",
        "        scores = cross_val_score(modelo, X_train_r_scaled, y_train_r, cv=5, scoring='neg_mean_squared_error')\n",
        "\n",
        "    # Almacenar resultados de validación cruzada\n",
        "    cv_scores[nombre] = {\n",
        "        'mean_score': scores.mean(),        # Promedio de scores entre los k folds\n",
        "        'std_score': scores.std(),          # Desviación estándar (mide variabilidad)\n",
        "        'rmse_cv': np.sqrt(-scores.mean())  # Convertir MSE negativo a RMSE positivo\n",
        "    }\n",
        "\n",
        "    # Mostrar RMSE ± desviación (menor RMSE y menor desviación = mejor modelo)\n",
        "    print(f\"{nombre:20} | RMSE: {np.sqrt(-scores.mean()):.4f} ± {np.sqrt(scores.std()):.4f}\")\n",
        "\n",
        "# Visualizar resultados de validación cruzada\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "nombres = list(cv_scores.keys())\n",
        "rmse_values = [cv_scores[n]['rmse_cv'] for n in nombres]\n",
        "std_values = [cv_scores[n]['std_score'] for n in nombres]\n",
        "\n",
        "# Gráfico de barras con barras de error (yerr) para mostrar variabilidad entre folds\n",
        "# capsize: Tamaño de las \"tapas\" en las barras de error\n",
        "plt.bar(nombres, rmse_values, yerr=std_values, capsize=5, alpha=0.7, color='lightcoral')\n",
        "plt.title('RMSE con Validación Cruzada')\n",
        "plt.ylabel('RMSE')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "# Scores negativos porque sklearn maximiza, pero MSE se minimiza\n",
        "plt.bar(nombres, [cv_scores[n]['mean_score'] for n in nombres],\n",
        "        yerr=[cv_scores[n]['std_score'] for n in nombres],\n",
        "        capsize=5, alpha=0.7, color='lightblue')\n",
        "plt.title('Score Promedio (Negativo MSE)')\n",
        "plt.ylabel('Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scores\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8whFavIYFL7R"
      },
      "source": [
        "---\n",
        "\n",
        "## Resumen: Caso 1 - Calibración de Sensores\n",
        "\n",
        "### Problema de Ingeniería Electrónica\n",
        "- **Sensor de temperatura con desgaste** → Relación voltaje-temperatura distorsionada\n",
        "- **Solución**: Modelo de regresión lineal para calibración\n",
        "\n",
        "### Resultados Obtenidos\n",
        "- **Ecuación**: `T = -1.26 + 21.18 × V`\n",
        "- **RMSE**: 0.60°C (excelente precisión)\n",
        "- **R²**: 0.9997 (99.97% de varianza explicada)\n",
        "\n",
        "### Aplicaciones Prácticas\n",
        "- Sistemas de control de temperatura\n",
        "- Instrumentación industrial\n",
        "- Monitoreo ambiental\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W66nWFPiFL7S"
      },
      "source": [
        "## Resumen: Caso 2 - Fabricación de Resistencias\n",
        "\n",
        "### Problema de Manufactura Compleja\n",
        "- **4 Variables de proceso**: Temperatura, tiempo, espesor, dopante\n",
        "- **Objetivo**: Optimizar resistencia del componente\n",
        "\n",
        "### Comparación de Modelos\n",
        "\n",
        "| Modelo              | RMSE       | R²         | Características        |\n",
        "|---------------------|-----------:|-----------:|------------------------|\n",
        "| Regresión Lineal    | 0.0005     |     0.7478 | Simple, interpretable  |\n",
        "| Ridge (α=0.1)       | 0.0005     |     0.7479 | Regularización L2      |\n",
        "| Lasso (α=0.01)      | 0.0009     |     -0.0859| Selección de variables |\n",
        "| **Random Forest**   | **0.0004** | **0.8202** | **Mejor rendimiento**  |\n",
        "\n",
        "### Lecciones Aprendidas\n",
        "- **Estandarización crucial** para modelos lineales\n",
        "- **Random Forest** maneja relaciones no lineales\n",
        "- **Lasso** puede fallar con múltiples variables importantes\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMh1xC93FL7S"
      },
      "source": [
        "## Técnicas Avanzadas: Validación Cruzada y Grid Search\n",
        "\n",
        "### ¿Por qué Validación Cruzada?\n",
        "- **Problema**: Una sola división train/test puede ser sesgada\n",
        "- **Solución**: K-Fold CV divide datos en K partes, entrena K veces\n",
        "- **Beneficio**: Estimación más robusta del rendimiento\n",
        "\n",
        "### Grid Search con CV\n",
        "```python\n",
        "param_grid = {'alpha': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]}\n",
        "grid_search = GridSearchCV(Ridge(), param_grid, cv=5)\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "```\n",
        "\n",
        "### Resultados de CV (5-fold)\n",
        "- **Linear Regression**: RMSE = 0.0006 ± 0.0004\n",
        "- **Ridge (optimizado)**: RMSE = 0.0006 ± 0.0005  \n",
        "- **Random Forest**: RMSE = 0.0006 ± 0.0005\n",
        "\n",
        "### Interpretación\n",
        "- **±** indica **variabilidad** entre folds (menor = más estable)\n",
        "- **Todos los modelos** muestran rendimiento similar y estable\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XV9vS4eDFL7S"
      },
      "source": [
        "## Métricas de Evaluación en Regresión\n",
        "\n",
        "### Principales Métricas Utilizadas\n",
        "\n",
        "#### 1. **RMSE (Root Mean Square Error)**\n",
        "\n",
        "- **Fórmula**: $\\sqrt{\\sum (y_\\textsf{real} - y_\\textsf{pred})^2 / n}$\n",
        "- **Ventajas**: Mismas unidades que variable objetivo, penaliza errores grandes\n",
        "- **Interpretación**: Menor = mejor\n",
        "\n",
        "#### 2. **R² (Coeficiente de Determinación)**\n",
        "\n",
        "- **Rango**: 0 a 1 (puede ser negativo si modelo es muy malo)\n",
        "- **Interpretación**: % de varianza explicada por el modelo\n",
        "- **R² = 0.82** → Modelo explica 82% de la variabilidad\n",
        "\n",
        "#### 3. **MAE (Mean Absolute Error)**\n",
        "\n",
        "- **Fórmula**: $\\sum |y_\\textsf{real} - y_\\textsf{pred}| / n$\n",
        "- **Ventaja**: Menos sensible a outliers que RMSE\n",
        "- **Uso**: Complementa RMSE para análisis completo\n",
        "\n",
        "### Análisis de Residuos\n",
        "\n",
        "- **Residuos**: $y_\\textsf{real} - y_\\textsf{pred}$\n",
        "- **Ideal**: Distribuidos aleatoriamente alrededor de 0\n",
        "- **Problemas**: Patrones indican falta de ajuste del modelo\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCOP_VErFL7S"
      },
      "source": [
        "## Comparación de Algoritmos de Regresión\n",
        "\n",
        "### **Linear Regression**\n",
        "- ✓ Simple e interpretable\n",
        "- ✓ Rápido de entrenar\n",
        "- ✕ Asume relación lineal\n",
        "- ✕ Sensible a outliers y multicolinealidad\n",
        "\n",
        "### **Ridge Regression (L2)**\n",
        "- ✓ Controla sobreajuste con regularización  \n",
        "- ✓ Maneja multicolinealidad\n",
        "- ✓ Todos los coeficientes se mantienen (≠ 0)\n",
        "- ✕ No elimina variables irrelevantes\n",
        "\n",
        "### **Lasso Regression (L1)**  \n",
        "- ✓ Selección automática de variables (coef → 0)\n",
        "- ✓ Produce modelos más simples\n",
        "- ✕ Puede eliminar variables importantes\n",
        "- ✕ Inestable con variables correlacionadas\n",
        "\n",
        "### **Random Forest**\n",
        "- ✓ Maneja relaciones no lineales\n",
        "- ✓ Robusto a outliers\n",
        "- ✓ No requiere estandarización\n",
        "- ✕ Menos interpretable (\"caja negra\")\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3Pns2R5FL7T"
      },
      "source": [
        "## Conclusiones y Recomendaciones\n",
        "\n",
        "### 🎯 **Principales Aprendizajes**\n",
        "\n",
        "1. **Preprocesamiento es crítico**\n",
        "   - Estandarización obligatoria para Ridge/Lasso\n",
        "   - Análisis exploratorio revela patrones importantes\n",
        "\n",
        "2. **No hay modelo universalmente mejor**\n",
        "   - Linear: Simplicidad e interpretabilidad\n",
        "   - Random Forest: Mejor rendimiento en datos complejos  \n",
        "   - Ridge: Equilibrio entre sesgo y varianza\n",
        "\n",
        "3. **Validación cruzada es esencial**\n",
        "   - Una sola división train/test puede engañar\n",
        "   - Grid Search automatiza optimización de hiperparámetros\n",
        "\n",
        "### 💡 **Recomendaciones Prácticas**\n",
        "\n",
        "- **Empezar simple**: Linear Regression como baseline\n",
        "- **Probar regularización**: Ridge si hay multicolinealidad  \n",
        "- **Considerar ensemble**: Random Forest para relaciones complejas\n",
        "- **Siempre validar**: Cross-validation + métricas múltiples\n",
        "- **Interpretar residuos**: Detecta problemas del modelo\n",
        "\n",
        "### 🚀 **Próximos Pasos**\n",
        "- Explorar otros algoritmos (SVM, Neural Networks)\n",
        "- Técnicas de feature engineering más avanzadas\n",
        "- Optimización bayesiana de hiperparámetros\n",
        "\n",
        "---\n",
        "\n",
        "### ¡Gracias por su atención!\n",
        "### ¿Preguntas?\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Ambiente ML",
      "language": "python",
      "name": "ml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
