{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Árboles de Clasificación y Bosques Aleatorios\n",
        "## Machine Learning - Encuentro sobre Modelos de Ensemble\n",
        "\n",
        "---\n",
        "\n",
        "## Contenido\n",
        "\n",
        "1. [Introducción y Conceptos Fundamentales](#introduccion)\n",
        "2. [Árboles de Decisión para Clasificación](#arboles-decision)\n",
        "3. [Bosques Aleatorios (Random Forest)](#bosques-aleatorios)\n",
        "4. [Aplicaciones Prácticas en Ingeniería Electrónica](#aplicaciones)\n",
        "5. [Métricas de Evaluación](#metricas)\n",
        "6. [Optimización de Hiperparámetros](#optimizacion)\n",
        "7. [Comparación con Otros Algoritmos](#comparacion)\n",
        "8. [Resumen y Conclusiones](#resumen)\n",
        "Árboles de Clasificación y Bosques Aleatorios  \n",
        "---\n",
        "\n",
        "<a id=\"introduccion\"></a>\n",
        "## 1. ¿Qué son los Árboles de Decisión?\n",
        "\n",
        "### Concepto Simple\n",
        "Los **árboles de decisión** son algoritmos que aprenden reglas simples basadas en las características de los datos para clasificar o predecir. Funcionan como un sistema de preguntas que guían hacia una decisión.\n",
        "\n",
        "### Analogía Visual\n",
        "Imagine que necesita diagnosticar una falla en un circuito electrónico. El árbol le pregunta:\n",
        "1. ¿El voltaje está dentro del rango normal? → Sí\n",
        "2. ¿La corriente supera el umbral seguro? → No  \n",
        "3. ¿La temperatura del componente es elevada? → Sí\n",
        "4. **Decisión**: Componente con degradación térmica\n",
        "\n",
        "### Estructura de un Árbol\n",
        "![](arbol_decision.svg){width=\"400\"}\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Los 4 Conceptos Fundamentales\n",
        "\n",
        "### 2.1 Nodos y Ramas\n",
        "- **Nodo Raíz**: La primera pregunta/división\n",
        "- **Nodos Internos**: Preguntas intermedias\n",
        "- **Nodos Hoja**: Decisiones finales (clases)\n",
        "- **Ramas**: Conexiones entre nodos basadas en condiciones\n",
        "\n",
        "### 2.2 Impureza (Gini / Entropía)\n",
        "- **Qué es**: Mide qué tan \"mezcladas\" están las clases en un nodo\n",
        "- **Objetivo**: Minimizar la impureza en cada división\n",
        "- **Fórmulas**:\n",
        "  - $\\textsf{Gini} = 1 - \\sum_{i=1}^{c} p_i^2$ (donde $p_i$ es la proporción de clase $i$)\n",
        "  - $\\textsf{Entropía} = -\\sum_{i=1}^{c} p_i \\log_2(p_i)$\n",
        "- **Valores**:\n",
        "  - **0**: Nodo puro (una sola clase)\n",
        "  - **1 (Gini) o log(c) (Entropía)**: Máxima mezcla de clases\n",
        "\n",
        "### 2.3 Ganancia de Información\n",
        "- **Qué es**: Diferencia de impureza antes y después de una división\n",
        "- **Objetivo**: Maximizar la ganancia para elegir la mejor división\n",
        "- **Fórmula**: $\\textsf{Ganancia} = \\textsf{Impureza}_\\textsf{padre} - \\sum_\\textsf{hijos} \\frac{n_\\textsf{hijo}}{n_\\textsf{padre}} \\times \\textsf{Impureza}_\\textsf{hijo}$\n",
        "- **Resultado**: El atributo con mayor ganancia se elige para dividir\n",
        "\n",
        "### 2.4 Poda (Pruning)\n",
        "- **Qué es**: Reducir la complejidad del árbol eliminando ramas poco útiles\n",
        "- **Tipos**:\n",
        "  - **Poda preventiva**: Limitar profundidad durante construcción\n",
        "  - **Poda posterior**: Eliminar ramas después de construir el árbol completo\n",
        "- **Ventaja**: Reduce sobreajuste y mejora generalización\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Parámetros Principales\n",
        "\n",
        "### Parámetro max_depth (Profundidad Máxima)\n",
        "| Valor             | Significado                   | Uso Recomendado         |\n",
        "|-------------------|-------------------------------|-------------------------|\n",
        "| max_depth alto    | Árbol complejo, muchas reglas | Riesgo de sobreajuste   |\n",
        "| max_depth bajo    | Árbol simple, pocas reglas    | Mejor generalización    |\n",
        "| **Valor inicial** | max_depth=None (sin límite)   | Ajustar según necesidad |\n",
        "\n",
        "### Parámetro min_samples_split (Mínimo de Muestras para Dividir)\n",
        "| Valor                  | Significado                    | Uso Recomendado      |\n",
        "|------------------------|--------------------------------|----------------------|\n",
        "| min_samples_split bajo | Más divisiones, árbol complejo | Puede sobreajustar   |\n",
        "| min_samples_split alto | Menos divisiones, árbol simple | Mejor generalización |\n",
        "| **Valor inicial**      | min_samples_split=2            | Valor estándar       |\n",
        "\n",
        "### Parámetro min_samples_leaf (Mínimo de Muestras por Hoja)\n",
        "| Valor              | Significado                | Uso Recomendado       |\n",
        "|--------------------|----------------------------|-----------------------|\n",
        "| min_samples_leaf=1 | Hojas con una sola muestra | Riesgo de sobreajuste |\n",
        "| min_samples_leaf=5 | Hojas más robustas         | Mejor generalización  |\n",
        "| **Valor inicial**  | min_samples_leaf=1         | Ajustar según dataset |\n",
        "\n",
        "---\n",
        "\n",
        "## 4. ¿Cuándo Usar Árboles de Decisión?\n",
        "\n",
        "### Ventajas\n",
        "- **Altamente interpretable**: Reglas claras y fáciles de entender\n",
        "- **No requiere normalización**: Funciona con datos en diferentes escalas\n",
        "- **Maneja datos no lineales**: Captura relaciones complejas\n",
        "- **Detecta variables importantes**: Automáticamente identifica características relevantes\n",
        "- **Maneja valores faltantes**: Puede trabajar con datos incompletos\n",
        "\n",
        "### Desventajas\n",
        "- **Sensible a pequeños cambios**: Pequeños cambios en datos pueden cambiar el árbol\n",
        "- **Propenso a sobreajuste**: Puede memorizar datos de entrenamiento\n",
        "- **Puede ser inestable**: Un solo cambio puede cambiar completamente la estructura\n",
        "- **Sesgo hacia atributos con más valores**: Puede favorecer variables con muchas categorías\n",
        "\n",
        "### Cuándo Usar\n",
        "- Necesitas interpretabilidad y explicabilidad\n",
        "- Trabajas con datos no lineales\n",
        "- Quieres identificar variables importantes\n",
        "- Dataset pequeño a mediano\n",
        "- Necesitas reglas de decisión claras\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"arboles-decision\"></a>\n",
        "## 5. Árboles de Decisión para Clasificación [⬆](#introduccion)\n",
        "\n",
        "### Ejemplo Práctico: Clasificación de Componentes Electrónicos\n",
        "\n",
        "Vamos a trabajar con un ejemplo realista: **clasificar el estado de integridad de componentes electrónicos** basándonos en mediciones físicas y eléctricas.\n",
        "\n",
        "**Características**:\n",
        "- Voltaje de operación (V)\n",
        "- Corriente de consumo (mA)\n",
        "- Temperatura de operación (°C)\n",
        "- Factor de potencia\n",
        "- Frecuencia de resonancia (kHz)\n",
        "\n",
        "**Clases**:\n",
        "- **0**: Componente funcional\n",
        "- **1**: Componente con degradación leve\n",
        "- **2**: Componente con falla crítica\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importar librerías necesarias\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.metrics import (accuracy_score, classification_report, confusion_matrix,\n",
        "                            ConfusionMatrixDisplay, roc_curve, auc)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configurar estilo de gráficos\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"Librerías importadas correctamente\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generar dataset sintético: Componentes Electrónicos\n",
        "np.random.seed(42)\n",
        "n_muestras = 500\n",
        "\n",
        "# Generar características relacionadas con el estado del componente\n",
        "# Componentes funcionales (clase 0): parámetros normales\n",
        "n_funcionales = 200\n",
        "voltaje_0 = np.random.normal(5.0, 0.3, n_funcionales)  # Voltaje estable alrededor de 5V\n",
        "corriente_0 = np.random.normal(100, 10, n_funcionales)  # Corriente normal ~100mA\n",
        "temperatura_0 = np.random.normal(45, 5, n_funcionales)  # Temperatura normal ~45°C\n",
        "factor_potencia_0 = np.random.normal(0.95, 0.03, n_funcionales)  # Factor de potencia alto\n",
        "frecuencia_0 = np.random.normal(1000, 50, n_funcionales)  # Frecuencia de resonancia normal\n",
        "\n",
        "# Componentes con degradación leve (clase 1): algunos parámetros fuera de rango\n",
        "n_degradados = 200\n",
        "voltaje_1 = np.random.normal(5.5, 0.5, n_degradados)  # Voltaje ligeramente elevado\n",
        "corriente_1 = np.random.normal(120, 15, n_degradados)  # Corriente aumentada\n",
        "temperatura_1 = np.random.normal(60, 8, n_degradados)  # Temperatura elevada\n",
        "factor_potencia_1 = np.random.normal(0.75, 0.1, n_degradados)  # Factor de potencia bajo\n",
        "frecuencia_1 = np.random.normal(950, 80, n_degradados)  # Frecuencia desviada\n",
        "\n",
        "# Componentes con falla crítica (clase 2): parámetros muy fuera de rango\n",
        "n_fallados = 100\n",
        "voltaje_2 = np.random.normal(6.5, 1.0, n_fallados)  # Voltaje muy alto\n",
        "corriente_2 = np.random.normal(180, 30, n_fallados)  # Corriente muy alta\n",
        "temperatura_2 = np.random.normal(85, 15, n_fallados)  # Temperatura crítica\n",
        "factor_potencia_2 = np.random.normal(0.5, 0.15, n_fallados)  # Factor de potencia muy bajo\n",
        "frecuencia_2 = np.random.normal(800, 100, n_fallados)  # Frecuencia muy desviada\n",
        "\n",
        "# Combinar todos los datos\n",
        "voltaje = np.concatenate([voltaje_0, voltaje_1, voltaje_2])\n",
        "corriente = np.concatenate([corriente_0, corriente_1, corriente_2])\n",
        "temperatura = np.concatenate([temperatura_0, temperatura_1, temperatura_2])\n",
        "factor_potencia = np.concatenate([factor_potencia_0, factor_potencia_1, factor_potencia_2])\n",
        "frecuencia = np.concatenate([frecuencia_0, frecuencia_1, frecuencia_2])\n",
        "\n",
        "# Crear etiquetas: 0=funcional, 1=degradado, 2=fallado\n",
        "etiquetas = np.concatenate([\n",
        "    np.zeros(n_funcionales, dtype=int),\n",
        "    np.ones(n_degradados, dtype=int),\n",
        "    np.full(n_fallados, 2, dtype=int)\n",
        "])\n",
        "\n",
        "# Crear DataFrame\n",
        "df_componentes = pd.DataFrame({\n",
        "    'voltaje': voltaje,\n",
        "    'corriente': corriente,\n",
        "    'temperatura': temperatura,\n",
        "    'factor_potencia': factor_potencia,\n",
        "    'frecuencia': frecuencia,\n",
        "    'estado': etiquetas\n",
        "})\n",
        "\n",
        "print(\"Dataset generado:\")\n",
        "print(f\"Muestras totales: {len(df_componentes)}\")\n",
        "print(f\"\\nDistribución por clase:\")\n",
        "print(df_componentes['estado'].value_counts().sort_index())\n",
        "print(f\"\\nPrimeras 10 muestras:\")\n",
        "print(df_componentes.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualización exploratoria de los datos\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "\n",
        "# Mapeo de colores para las clases\n",
        "colores = {0: 'green', 1: 'orange', 2: 'red'}\n",
        "nombres_clases = {0: 'Funcional', 1: 'Degradado', 2: 'Falla Crítica'}\n",
        "\n",
        "# Gráfico 1: Voltaje vs Corriente\n",
        "ax = axes[0, 0]\n",
        "for clase in [0, 1, 2]:\n",
        "    mask = df_componentes['estado'] == clase\n",
        "    ax.scatter(df_componentes[mask]['voltaje'], df_componentes[mask]['corriente'],\n",
        "               c=colores[clase], label=nombres_clases[clase], alpha=0.6, s=50)\n",
        "ax.set_xlabel('Voltaje (V)')\n",
        "ax.set_ylabel('Corriente (mA)')\n",
        "ax.set_title('Voltaje vs Corriente por Estado')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Gráfico 2: Temperatura vs Factor de Potencia\n",
        "ax = axes[0, 1]\n",
        "for clase in [0, 1, 2]:\n",
        "    mask = df_componentes['estado'] == clase\n",
        "    ax.scatter(df_componentes[mask]['temperatura'], df_componentes[mask]['factor_potencia'],\n",
        "               c=colores[clase], label=nombres_clases[clase], alpha=0.6, s=50)\n",
        "ax.set_xlabel('Temperatura (°C)')\n",
        "ax.set_ylabel('Factor de Potencia')\n",
        "ax.set_title('Temperatura vs Factor de Potencia')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Gráfico 3: Frecuencia por Estado\n",
        "ax = axes[0, 2]\n",
        "df_componentes.boxplot(column='frecuencia', by='estado', ax=ax)\n",
        "ax.set_xlabel('Estado del Componente')\n",
        "ax.set_ylabel('Frecuencia (kHz)')\n",
        "ax.set_title('Distribución de Frecuencia por Estado')\n",
        "ax.set_xticklabels(['Funcional', 'Degradado', 'Falla Crítica'])\n",
        "plt.suptitle('')  # Eliminar título automático\n",
        "\n",
        "# Gráfico 4: Matriz de correlación\n",
        "ax = axes[1, 0]\n",
        "correlation_matrix = df_componentes.iloc[:, :-1].corr()\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,\n",
        "            square=True, fmt='.2f', ax=ax)\n",
        "ax.set_title('Matriz de Correlación entre Características')\n",
        "\n",
        "# Gráfico 5: Distribución de Temperatura\n",
        "ax = axes[1, 1]\n",
        "for clase in [0, 1, 2]:\n",
        "    mask = df_componentes['estado'] == clase\n",
        "    ax.hist(df_componentes[mask]['temperatura'], bins=20, alpha=0.6,\n",
        "            label=nombres_clases[clase], color=colores[clase])\n",
        "ax.set_xlabel('Temperatura (°C)')\n",
        "ax.set_ylabel('Frecuencia')\n",
        "ax.set_title('Distribución de Temperatura por Estado')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Gráfico 6: Distribución de Voltaje\n",
        "ax = axes[1, 2]\n",
        "for clase in [0, 1, 2]:\n",
        "    mask = df_componentes['estado'] == clase\n",
        "    ax.hist(df_componentes[mask]['voltaje'], bins=20, alpha=0.6,\n",
        "            label=nombres_clases[clase], color=colores[clase])\n",
        "ax.set_xlabel('Voltaje (V)')\n",
        "ax.set_ylabel('Frecuencia')\n",
        "ax.set_title('Distribución de Voltaje por Estado')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dividir datos en entrenamiento y prueba\n",
        "X = df_componentes[['voltaje', 'corriente', 'temperatura', 'factor_potencia', 'frecuencia']]\n",
        "y = df_componentes['estado']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"Entrenamiento: {len(X_train)} muestras\")\n",
        "print(f\"Prueba: {len(X_test)} muestras\")\n",
        "print(f\"\\nDistribución en entrenamiento:\")\n",
        "print(y_train.value_counts().sort_index())\n",
        "print(f\"\\nDistribución en prueba:\")\n",
        "print(y_test.value_counts().sort_index())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Entrenar árbol de decisión básico (sin restricciones)\n",
        "arbol_basico = DecisionTreeClassifier(random_state=42)\n",
        "arbol_basico.fit(X_train, y_train)\n",
        "\n",
        "# Predecir\n",
        "y_pred_basico = arbol_basico.predict(X_test)\n",
        "\n",
        "# Calcular métricas\n",
        "accuracy_basico = accuracy_score(y_test, y_pred_basico)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"ÁRBOL DE DECISIÓN BÁSICO (sin restricciones)\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Precisión (Accuracy): {accuracy_basico:.4f}\")\n",
        "print(f\"Profundidad del árbol: {arbol_basico.get_depth()}\")\n",
        "print(f\"Número de nodos hoja: {arbol_basico.get_n_leaves()}\")\n",
        "print(\"\\nReporte de clasificación:\")\n",
        "print(classification_report(y_test, y_pred_basico,\n",
        "                           target_names=['Funcional', 'Degradado', 'Falla Crítica']))\n",
        "\n",
        "# Matriz de confusión\n",
        "cm_basico = confusion_matrix(y_test, y_pred_basico)\n",
        "print(\"\\nMatriz de confusión:\")\n",
        "print(cm_basico)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizar el árbol de decisión (primeros niveles para legibilidad)\n",
        "plt.figure(figsize=(20, 12))\n",
        "plot_tree(arbol_basico,\n",
        "          feature_names=['Voltaje', 'Corriente', 'Temperatura', 'Factor Potencia', 'Frecuencia'],\n",
        "          class_names=['Funcional', 'Degradado', 'Falla Crítica'],\n",
        "          filled=True,\n",
        "          rounded=True,\n",
        "          fontsize=10,\n",
        "          max_depth=3)  # Mostrar solo primeros 3 niveles\n",
        "plt.title(\"Árbol de Decisión (Primeros 3 niveles)\", fontsize=16, pad=20)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imprimir las reglas de decisión en texto (primeros niveles)\n",
        "reglas_texto = export_text(arbol_basico,\n",
        "                           feature_names=['Voltaje', 'Corriente', 'Temperatura', 'Factor Potencia', 'Frecuencia'],\n",
        "                           max_depth=3,\n",
        "                           decimals=2)\n",
        "print(\"Reglas de Decisión (Primeros 3 niveles):\")\n",
        "print(\"=\" * 60)\n",
        "print(reglas_texto)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comparar árboles con diferentes profundidades máximas\n",
        "profundidades = [3, 5, 7, 10, 15, None]\n",
        "resultados_profundidad = []\n",
        "\n",
        "for max_d in profundidades:\n",
        "    arbol = DecisionTreeClassifier(max_depth=max_d, random_state=42)\n",
        "    arbol.fit(X_train, y_train)\n",
        "\n",
        "    # Predecir\n",
        "    y_pred_train = arbol.predict(X_train)\n",
        "    y_pred_test = arbol.predict(X_test)\n",
        "\n",
        "    # Calcular métricas\n",
        "    acc_train = accuracy_score(y_train, y_pred_train)\n",
        "    acc_test = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "    resultados_profundidad.append({\n",
        "        'max_depth': max_d if max_d is not None else 'Sin límite',\n",
        "        'profundidad_real': arbol.get_depth(),\n",
        "        'nodos_hoja': arbol.get_n_leaves(),\n",
        "        'acc_train': acc_train,\n",
        "        'acc_test': acc_test\n",
        "    })\n",
        "\n",
        "df_profundidades = pd.DataFrame(resultados_profundidad)\n",
        "print(\"Comparación de Árboles con Diferentes Profundidades:\")\n",
        "print(\"=\" * 70)\n",
        "print(df_profundidades.to_string(index=False))\n",
        "\n",
        "# Visualizar resultados\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "# Gráfico 1: Accuracy vs Profundidad\n",
        "ax = axes[0]\n",
        "x_pos = range(len(df_profundidades))\n",
        "ax.plot(x_pos, df_profundidades['acc_train'], 'o-', label='Entrenamiento', linewidth=2, markersize=8)\n",
        "ax.plot(x_pos, df_profundidades['acc_test'], 's-', label='Prueba', linewidth=2, markersize=8)\n",
        "ax.set_xticks(x_pos)\n",
        "ax.set_xticklabels(df_profundidades['max_depth'], rotation=45)\n",
        "ax.set_xlabel('Profundidad Máxima')\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.set_title('Accuracy vs Profundidad Máxima')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Gráfico 2: Número de Nodos Hoja vs Profundidad\n",
        "ax = axes[1]\n",
        "ax.bar(x_pos, df_profundidades['nodos_hoja'], alpha=0.7, color='skyblue')\n",
        "ax.set_xticks(x_pos)\n",
        "ax.set_xticklabels(df_profundidades['max_depth'], rotation=45)\n",
        "ax.set_xlabel('Profundidad Máxima')\n",
        "ax.set_ylabel('Número de Nodos Hoja')\n",
        "ax.set_title('Complejidad del Árbol')\n",
        "ax.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Gráfico 3: Diferencia entre Train y Test (sobreajuste)\n",
        "ax = axes[2]\n",
        "diferencia = df_profundidades['acc_train'] - df_profundidades['acc_test']\n",
        "ax.bar(x_pos, diferencia, alpha=0.7, color='coral')\n",
        "ax.set_xticks(x_pos)\n",
        "ax.set_xticklabels(df_profundidades['max_depth'], rotation=45)\n",
        "ax.set_xlabel('Profundidad Máxima')\n",
        "ax.set_ylabel('Diferencia (Train - Test)')\n",
        "ax.set_title('Indicador de Sobreajuste')\n",
        "ax.axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
        "ax.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Identificar mejor árbol (balance entre accuracy y generalización)\n",
        "# Penalizar sobreajuste: score = acc_test - 0.5 * (acc_train - acc_test)\n",
        "df_profundidades['score_balanceado'] = (df_profundidades['acc_test'] -\n",
        "                                        0.5 * (df_profundidades['acc_train'] - df_profundidades['acc_test']))\n",
        "mejor_idx = df_profundidades['score_balanceado'].idxmax()\n",
        "mejor_profundidad = df_profundidades.loc[mejor_idx, 'max_depth']\n",
        "\n",
        "print(f\"\\nMejor profundidad (balance entre accuracy y generalización): {mejor_profundidad}\")\n",
        "print(f\"Accuracy en prueba: {df_profundidades.loc[mejor_idx, 'acc_test']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"bosques-aleatorios\"></a>\n",
        "## 6. Bosques Aleatorios (Random Forest) [⬆](#introduccion)\n",
        "\n",
        "### ¿Qué es un Bosque Aleatorio?\n",
        "\n",
        "Un **Bosque Aleatorio** es un algoritmo de **ensemble** (conjunto) que combina múltiples árboles de decisión para mejorar la precisión y reducir el sobreajuste.\n",
        "\n",
        "### Concepto Simple\n",
        "En lugar de confiar en un solo árbol, entrenamos **cientos de árboles** y tomamos la decisión por **votación mayoritaria**.\n",
        "\n",
        "### Analogía\n",
        "Imagine que necesita diagnosticar una falla. En lugar de preguntar a un solo experto:\n",
        "- Árbol de Decisión: Un experto hace todas las preguntas\n",
        "- Bosque Aleatorio: 100 expertos, cada uno hace preguntas diferentes, y votamos por la respuesta más común\n",
        "\n",
        "### Los 3 Conceptos Fundamentales\n",
        "\n",
        "#### 6.1 Bootstrap Aggregating (Bagging)\n",
        "- **Qué es**: Cada árbol se entrena con una **muestra aleatoria** de los datos (con reemplazo)\n",
        "- **Ventaja**: Cada árbol ve datos ligeramente diferentes, reduciendo varianza\n",
        "\n",
        "#### 6.2 Selección Aleatoria de Características\n",
        "- **Qué es**: En cada división, solo se consideran un **subconjunto aleatorio** de características\n",
        "- **Valor típico**: $\\sqrt{n}$ características para clasificación (donde $n$ es el total de características)\n",
        "- **Ventaja**: Reduce correlación entre árboles y mejora diversidad\n",
        "\n",
        "#### 6.3 Votación Mayoritaria\n",
        "- **Qué es**: La clase predicha es la que más árboles votaron\n",
        "- **Para probabilidades**: Promedio de probabilidades de todos los árboles\n",
        "\n",
        "### Parámetros Principales\n",
        "\n",
        "| Parámetro           | Descripción                          | Valor Recomendado      |\n",
        "|---------------------|--------------------------------------|------------------------|\n",
        "| **n_estimators**    | Número de árboles en el bosque       | 100-200 (más = mejor, pero más lento) |\n",
        "| **max_depth**       | Profundidad máxima de cada árbol     | None o 10-20           |\n",
        "| **min_samples_split** | Mínimo muestras para dividir      | 2 o más               |\n",
        "| **min_samples_leaf**  | Mínimo muestras por hoja            | 1 o más               |\n",
        "| **max_features**    | Número de características por división | 'sqrt' (clasificación) |\n",
        "\n",
        "### Ventajas sobre Árboles Individuales\n",
        "- **Menos sobreajuste**: Promediar múltiples árboles reduce varianza\n",
        "- **Mayor precisión**: Generalmente mejor rendimiento\n",
        "- **Robusto a outliers**: Diferentes árboles compensan errores\n",
        "- **Importancia de características**: Mide qué características son más relevantes\n",
        "- **Maneja datos desbalanceados**: Puede balancear clases\n",
        "\n",
        "### Desventajas\n",
        "- **Menos interpretable**: No puedes \"ver\" un solo árbol fácilmente\n",
        "- **Más lento**: Requiere entrenar múltiples árboles\n",
        "- **Más memoria**: Almacena múltiples modelos\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importar Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Entrenar un Bosque Aleatorio básico\n",
        "bosque_basico = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "bosque_basico.fit(X_train, y_train)\n",
        "\n",
        "# Predecir\n",
        "y_pred_bosque = bosque_basico.predict(X_test)\n",
        "\n",
        "# Calcular métricas\n",
        "accuracy_bosque = accuracy_score(y_test, y_pred_bosque)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"BOSQUE ALEATORIO BÁSICO (100 árboles)\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Precisión (Accuracy): {accuracy_bosque:.4f}\")\n",
        "print(\"\\nReporte de clasificación:\")\n",
        "print(classification_report(y_test, y_pred_bosque,\n",
        "                           target_names=['Funcional', 'Degradado', 'Falla Crítica']))\n",
        "\n",
        "# Matriz de confusión\n",
        "cm_bosque = confusion_matrix(y_test, y_pred_bosque)\n",
        "print(\"\\nMatriz de confusión:\")\n",
        "print(cm_bosque)\n",
        "\n",
        "# Comparar con árbol individual\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"COMPARACIÓN: Árbol Individual vs Bosque Aleatorio\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Árbol Individual (sin límite):     {accuracy_basico:.4f}\")\n",
        "print(f\"Bosque Aleatorio (100 árboles):    {accuracy_bosque:.4f}\")\n",
        "print(f\"Mejora:                            {accuracy_bosque - accuracy_basico:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizar importancia de características (Feature Importance)\n",
        "importancias = bosque_basico.feature_importances_\n",
        "caracteristicas = ['Voltaje', 'Corriente', 'Temperatura', 'Factor Potencia', 'Frecuencia']\n",
        "\n",
        "# Crear DataFrame para mejor visualización\n",
        "df_importancias = pd.DataFrame({\n",
        "    'Característica': caracteristicas,\n",
        "    'Importancia': importancias\n",
        "}).sort_values('Importancia', ascending=False)\n",
        "\n",
        "print(\"Importancia de Características (Feature Importance):\")\n",
        "print(\"=\" * 50)\n",
        "for idx, row in df_importancias.iterrows():\n",
        "    print(f\"{row['Característica']:20} : {row['Importancia']:.4f} ({row['Importancia']*100:.2f}%)\")\n",
        "\n",
        "# Visualizar importancia\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Gráfico de barras horizontal\n",
        "ax = axes[0]\n",
        "colores_barras = plt.cm.viridis(df_importancias['Importancia'] / df_importancias['Importancia'].max())\n",
        "ax.barh(df_importancias['Característica'], df_importancias['Importancia'], color=colores_barras)\n",
        "ax.set_xlabel('Importancia')\n",
        "ax.set_title('Importancia de Características - Bosque Aleatorio')\n",
        "ax.grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "# Gráfico de pastel\n",
        "ax = axes[1]\n",
        "ax.pie(df_importancias['Importancia'], labels=df_importancias['Característica'],\n",
        "       autopct='%1.1f%%', startangle=90)\n",
        "ax.set_title('Distribución de Importancia')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comparar diferentes números de árboles (n_estimators)\n",
        "n_arboles_lista = [10, 25, 50, 100, 200, 500]\n",
        "resultados_n_arboles = []\n",
        "\n",
        "for n_arboles in n_arboles_lista:\n",
        "    bosque = RandomForestClassifier(n_estimators=n_arboles, random_state=42, n_jobs=-1)\n",
        "    bosque.fit(X_train, y_train)\n",
        "\n",
        "    # Predecir\n",
        "    y_pred_train = bosque.predict(X_train)\n",
        "    y_pred_test = bosque.predict(X_test)\n",
        "\n",
        "    # Calcular métricas\n",
        "    acc_train = accuracy_score(y_train, y_pred_train)\n",
        "    acc_test = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "    # Tiempo de entrenamiento (aproximado)\n",
        "    import time\n",
        "    inicio = time.time()\n",
        "    bosque_temp = RandomForestClassifier(n_estimators=n_arboles, random_state=42, n_jobs=-1)\n",
        "    bosque_temp.fit(X_train, y_train)\n",
        "    tiempo = time.time() - inicio\n",
        "\n",
        "    resultados_n_arboles.append({\n",
        "        'n_estimators': n_arboles,\n",
        "        'acc_train': acc_train,\n",
        "        'acc_test': acc_test,\n",
        "        'tiempo_seg': tiempo\n",
        "    })\n",
        "\n",
        "df_n_arboles = pd.DataFrame(resultados_n_arboles)\n",
        "print(\"Comparación de Bosques con Diferentes Números de Árboles:\")\n",
        "print(\"=\" * 70)\n",
        "print(df_n_arboles.to_string(index=False))\n",
        "\n",
        "# Visualizar resultados\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Gráfico 1: Accuracy vs Número de Árboles\n",
        "ax = axes[0]\n",
        "ax.plot(df_n_arboles['n_estimators'], df_n_arboles['acc_train'], 'o-',\n",
        "        label='Entrenamiento', linewidth=2, markersize=8)\n",
        "ax.plot(df_n_arboles['n_estimators'], df_n_arboles['acc_test'], 's-',\n",
        "        label='Prueba', linewidth=2, markersize=8)\n",
        "ax.set_xlabel('Número de Árboles (n_estimators)')\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.set_title('Accuracy vs Número de Árboles')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Gráfico 2: Tiempo de Entrenamiento vs Número de Árboles\n",
        "ax = axes[1]\n",
        "ax.plot(df_n_arboles['n_estimators'], df_n_arboles['tiempo_seg'], 'ro-',\n",
        "        linewidth=2, markersize=8)\n",
        "ax.set_xlabel('Número de Árboles (n_estimators)')\n",
        "ax.set_ylabel('Tiempo de Entrenamiento (segundos)')\n",
        "ax.set_title('Costo Computacional')\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizar matrices de confusión comparativas\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Matriz de confusión - Árbol Individual\n",
        "ax = axes[0]\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, y_pred_basico,\n",
        "                                       display_labels=['Funcional', 'Degradado', 'Falla Crítica'],\n",
        "                                       ax=ax, cmap='Blues')\n",
        "ax.set_title('Árbol de Decisión Individual')\n",
        "ax.set_xlabel('Predicción')\n",
        "ax.set_ylabel('Valor Real')\n",
        "\n",
        "# Matriz de confusión - Bosque Aleatorio\n",
        "ax = axes[1]\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, y_pred_bosque,\n",
        "                                       display_labels=['Funcional', 'Degradado', 'Falla Crítica'],\n",
        "                                       ax=ax, cmap='Greens')\n",
        "ax.set_title('Bosque Aleatorio (100 árboles)')\n",
        "ax.set_xlabel('Predicción')\n",
        "ax.set_ylabel('Valor Real')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"aplicaciones\"></a>\n",
        "## 7. Aplicación Práctica: Clasificación de Fallas en Circuitos Integrados [⬆](#introduccion)\n",
        "\n",
        "Vamos a implementar un ejemplo más complejo: **detección de fallas en circuitos integrados** basándonos en pruebas funcionales.\n",
        "\n",
        "**Contexto**: En la fabricación de CI, cada chip se prueba con múltiples señales de entrada. Necesitamos clasificar si el chip es:\n",
        "- **Funcional** (pasa todas las pruebas)\n",
        "- **Fallado** (falla críticas)\n",
        "- **Marginal** (pasa pruebas pero con degradación)\n",
        "\n",
        "**Características**:\n",
        "- Respuesta a frecuencia alta (MHz)\n",
        "- Respuesta a frecuencia baja (Hz)\n",
        "- Consumo de potencia (mW)\n",
        "- Voltaje de umbral (V)\n",
        "- Tiempo de respuesta (ns)\n",
        "- Ganancia (dB)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generar dataset más complejo: Circuitos Integrados\n",
        "np.random.seed(123)\n",
        "n_chips = 800\n",
        "\n",
        "# Chips funcionales (clase 0): 60% de la producción\n",
        "n_funcionales = int(0.6 * n_chips)\n",
        "freq_alta_func = np.random.normal(100, 5, n_funcionales)  # MHz, respuesta a alta frecuencia\n",
        "freq_baja_func = np.random.normal(1, 0.1, n_funcionales)  # Hz, respuesta a baja frecuencia\n",
        "consumo_func = np.random.normal(50, 5, n_funcionales)     # mW, consumo normal\n",
        "voltaje_umbral_func = np.random.normal(0.7, 0.05, n_funcionales)  # V, voltaje umbral normal\n",
        "tiempo_respuesta_func = np.random.normal(10, 1, n_funcionales)    # ns, tiempo de respuesta rápido\n",
        "ganancia_func = np.random.normal(40, 2, n_funcionales)            # dB, ganancia alta\n",
        "\n",
        "# Chips marginales (clase 1): 30% de la producción\n",
        "n_marginales = int(0.3 * n_chips)\n",
        "freq_alta_marg = np.random.normal(95, 8, n_marginales)      # Frecuencia ligeramente reducida\n",
        "freq_baja_marg = np.random.normal(1.2, 0.2, n_marginales)  # Desviación en baja frecuencia\n",
        "consumo_marg = np.random.normal(65, 8, n_marginales)        # Consumo aumentado\n",
        "voltaje_umbral_marg = np.random.normal(0.75, 0.08, n_marginales)  # Voltaje umbral elevado\n",
        "tiempo_respuesta_marg = np.random.normal(15, 2, n_marginales)      # Respuesta más lenta\n",
        "ganancia_marg = np.random.normal(35, 3, n_marginales)               # Ganancia reducida\n",
        "\n",
        "# Chips fallados (clase 2): 10% de la producción\n",
        "n_fallados = n_chips - n_funcionales - n_marginales\n",
        "freq_alta_fall = np.random.normal(80, 15, n_fallados)      # Frecuencia muy reducida\n",
        "freq_baja_fall = np.random.normal(1.5, 0.5, n_fallados)   # Desviación significativa\n",
        "consumo_fall = np.random.normal(100, 20, n_fallados)       # Consumo excesivo\n",
        "voltaje_umbral_fall = np.random.normal(0.9, 0.15, n_fallados)  # Voltaje umbral muy alto\n",
        "tiempo_respuesta_fall = np.random.normal(30, 5, n_fallados)     # Respuesta muy lenta\n",
        "ganancia_fall = np.random.normal(25, 5, n_fallados)              # Ganancia muy baja\n",
        "\n",
        "# Combinar datos\n",
        "freq_alta = np.concatenate([freq_alta_func, freq_alta_marg, freq_alta_fall])\n",
        "freq_baja = np.concatenate([freq_baja_func, freq_baja_marg, freq_baja_fall])\n",
        "consumo = np.concatenate([consumo_func, consumo_marg, consumo_fall])\n",
        "voltaje_umbral = np.concatenate([voltaje_umbral_func, voltaje_umbral_marg, voltaje_umbral_fall])\n",
        "tiempo_respuesta = np.concatenate([tiempo_respuesta_func, tiempo_respuesta_marg, tiempo_respuesta_fall])\n",
        "ganancia = np.concatenate([ganancia_func, ganancia_marg, ganancia_fall])\n",
        "\n",
        "# Etiquetas: 0=funcional, 1=marginal, 2=fallado\n",
        "etiquetas_ci = np.concatenate([\n",
        "    np.zeros(n_funcionales, dtype=int),\n",
        "    np.ones(n_marginales, dtype=int),\n",
        "    np.full(n_fallados, 2, dtype=int)\n",
        "])\n",
        "\n",
        "# Crear DataFrame\n",
        "df_chips = pd.DataFrame({\n",
        "    'freq_alta': freq_alta,\n",
        "    'freq_baja': freq_baja,\n",
        "    'consumo': consumo,\n",
        "    'voltaje_umbral': voltaje_umbral,\n",
        "    'tiempo_respuesta': tiempo_respuesta,\n",
        "    'ganancia': ganancia,\n",
        "    'estado': etiquetas_ci\n",
        "})\n",
        "\n",
        "print(\"Dataset de Circuitos Integrados:\")\n",
        "print(f\"Muestras totales: {len(df_chips)}\")\n",
        "print(f\"\\nDistribución por clase:\")\n",
        "print(df_chips['estado'].value_counts().sort_index())\n",
        "print(\"\\nEstadísticas descriptivas:\")\n",
        "df_chips.describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dividir datos\n",
        "X_ci = df_chips[['freq_alta', 'freq_baja', 'consumo', 'voltaje_umbral', 'tiempo_respuesta', 'ganancia']]\n",
        "y_ci = df_chips['estado']\n",
        "\n",
        "X_train_ci, X_test_ci, y_train_ci, y_test_ci = train_test_split(\n",
        "    X_ci, y_ci, test_size=0.2, random_state=42, stratify=y_ci\n",
        ")\n",
        "\n",
        "print(f\"Entrenamiento: {len(X_train_ci)} muestras\")\n",
        "print(f\"Prueba: {len(X_test_ci)} muestras\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Entrenar múltiples modelos y comparar\n",
        "modelos_ci = {\n",
        "    'Árbol (max_depth=5)': DecisionTreeClassifier(max_depth=5, random_state=42),\n",
        "    'Árbol (max_depth=10)': DecisionTreeClassifier(max_depth=10, random_state=42),\n",
        "    'Bosque (50 árboles)': RandomForestClassifier(n_estimators=50, random_state=42),\n",
        "    'Bosque (100 árboles)': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    'Bosque (200 árboles)': RandomForestClassifier(n_estimators=200, random_state=42)\n",
        "}\n",
        "\n",
        "resultados_ci = {}\n",
        "\n",
        "print(\"Comparación de Modelos para Clasificación de Circuitos Integrados:\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "for nombre, modelo in modelos_ci.items():\n",
        "    modelo.fit(X_train_ci, y_train_ci)\n",
        "    y_pred_train = modelo.predict(X_train_ci)\n",
        "    y_pred_test = modelo.predict(X_test_ci)\n",
        "\n",
        "    acc_train = accuracy_score(y_train_ci, y_pred_train)\n",
        "    acc_test = accuracy_score(y_test_ci, y_pred_test)\n",
        "\n",
        "    resultados_ci[nombre] = {\n",
        "        'acc_train': acc_train,\n",
        "        'acc_test': acc_test\n",
        "    }\n",
        "\n",
        "    print(f\"{nombre:25} | Train: {acc_train:.4f} | Test: {acc_test:.4f}\")\n",
        "\n",
        "# Crear DataFrame de resultados\n",
        "df_resultados_ci = pd.DataFrame(resultados_ci).T\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "\n",
        "# Visualizar comparación\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Gráfico de barras: Accuracy\n",
        "ax = axes[0]\n",
        "x_pos = range(len(df_resultados_ci))\n",
        "width = 0.35\n",
        "ax.bar([x - width/2 for x in x_pos], df_resultados_ci['acc_train'],\n",
        "       width, label='Entrenamiento', alpha=0.8)\n",
        "ax.bar([x + width/2 for x in x_pos], df_resultados_ci['acc_test'],\n",
        "       width, label='Prueba', alpha=0.8)\n",
        "ax.set_xticks(x_pos)\n",
        "ax.set_xticklabels(df_resultados_ci.index, rotation=45, ha='right')\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.set_title('Comparación de Modelos')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Gráfico: Diferencia Train-Test (sobreajuste)\n",
        "ax = axes[1]\n",
        "diferencia = df_resultados_ci['acc_train'] - df_resultados_ci['acc_test']\n",
        "ax.bar(x_pos, diferencia, alpha=0.7, color='coral')\n",
        "ax.set_xticks(x_pos)\n",
        "ax.set_xticklabels(df_resultados_ci.index, rotation=45, ha='right')\n",
        "ax.set_ylabel('Diferencia (Train - Test)')\n",
        "ax.set_title('Indicador de Sobreajuste')\n",
        "ax.axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
        "ax.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Seleccionar mejor modelo\n",
        "mejor_modelo_nombre = df_resultados_ci['acc_test'].idxmax()\n",
        "mejor_modelo_acc = df_resultados_ci.loc[mejor_modelo_nombre, 'acc_test']\n",
        "print(f\"\\nMejor modelo: {mejor_modelo_nombre}\")\n",
        "print(f\"Accuracy en prueba: {mejor_modelo_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Entrenar el mejor modelo y obtener análisis detallado\n",
        "mejor_modelo_ci = RandomForestClassifier(n_estimators=200, random_state=42)\n",
        "mejor_modelo_ci.fit(X_train_ci, y_train_ci)\n",
        "y_pred_ci = mejor_modelo_ci.predict(X_test_ci)\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"ANÁLISIS DETALLADO - BOSQUE ALEATORIO (200 árboles)\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\\nReporte de clasificación:\")\n",
        "print(classification_report(y_test_ci, y_pred_ci,\n",
        "                           target_names=['Funcional', 'Marginal', 'Fallado']))\n",
        "\n",
        "# Matriz de confusión detallada\n",
        "cm_ci = confusion_matrix(y_test_ci, y_pred_ci)\n",
        "print(\"\\nMatriz de confusión (valores absolutos):\")\n",
        "print(cm_ci)\n",
        "\n",
        "# Matriz de confusión en porcentajes\n",
        "cm_ci_percent = cm_ci.astype('float') / cm_ci.sum(axis=1)[:, np.newaxis]\n",
        "print(\"\\nMatriz de confusión (porcentajes):\")\n",
        "np.set_printoptions(precision=2, suppress=True)\n",
        "print(cm_ci_percent)\n",
        "\n",
        "# Visualizar matriz de confusión\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(y_test_ci, y_pred_ci,\n",
        "                                       display_labels=['Funcional', 'Marginal', 'Fallado'],\n",
        "                                       ax=axes[0], cmap='Blues')\n",
        "axes[0].set_title('Matriz de Confusión (Valores Absolutos)')\n",
        "\n",
        "ConfusionMatrixDisplay(confusion_matrix=cm_ci_percent,\n",
        "                       display_labels=['Funcional', 'Marginal', 'Fallado']).plot(\n",
        "                       ax=axes[1], cmap='Blues', values_format='.2f')\n",
        "axes[1].set_title('Matriz de Confusión (Porcentajes)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Importancia de características\n",
        "importancias_ci = mejor_modelo_ci.feature_importances_\n",
        "caracteristicas_ci = ['Freq Alta', 'Freq Baja', 'Consumo', 'Voltaje Umbral',\n",
        "                     'Tiempo Respuesta', 'Ganancia']\n",
        "\n",
        "df_importancias_ci = pd.DataFrame({\n",
        "    'Característica': caracteristicas_ci,\n",
        "    'Importancia': importancias_ci\n",
        "}).sort_values('Importancia', ascending=False)\n",
        "\n",
        "print(\"\\nImportancia de Características:\")\n",
        "print(\"=\" * 50)\n",
        "for idx, row in df_importancias_ci.iterrows():\n",
        "    print(f\"{row['Característica']:20} : {row['Importancia']:.4f} ({row['Importancia']*100:.2f}%)\")\n",
        "\n",
        "# Visualizar importancia\n",
        "plt.figure(figsize=(10, 6))\n",
        "colores_ci = plt.cm.viridis(df_importancias_ci['Importancia'] / df_importancias_ci['Importancia'].max())\n",
        "plt.barh(df_importancias_ci['Característica'], df_importancias_ci['Importancia'],\n",
        "         color=colores_ci)\n",
        "plt.xlabel('Importancia')\n",
        "plt.title('Importancia de Características - Detección de Fallas en CI')\n",
        "plt.grid(True, alpha=0.3, axis='x')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"optimizacion\"></a>\n",
        "## 8. Optimización de Hiperparámetros con Grid Search [⬆](#introduccion)\n",
        "\n",
        "El **Grid Search** prueba sistemáticamente diferentes combinaciones de hiperparámetros para encontrar la mejor configuración.\n",
        "\n",
        "### Proceso:\n",
        "1. Definir una **grilla** de valores para cada parámetro\n",
        "2. Probar **todas las combinaciones**\n",
        "3. Evaluar con **validación cruzada**\n",
        "4. Seleccionar la **mejor combinación**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Grid Search para optimizar hiperparámetros del Bosque Aleatorio\n",
        "# Definir grilla de parámetros\n",
        "param_grid_bosque = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [5, 10, 15, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Crear GridSearchCV con validación cruzada (5-fold)\n",
        "grid_bosque = GridSearchCV(\n",
        "    RandomForestClassifier(random_state=42),\n",
        "    param_grid_bosque,\n",
        "    cv=5,                              # Validación cruzada de 5 folds\n",
        "    scoring='accuracy',                # Métrica a optimizar\n",
        "    n_jobs=-1,                         # Usar todos los núcleos disponibles\n",
        "    verbose=1                          # Mostrar progreso\n",
        ")\n",
        "\n",
        "print(\"Iniciando Grid Search (esto puede tomar unos minutos)...\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Entrenar con todas las combinaciones\n",
        "grid_bosque.fit(X_train_ci, y_train_ci)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"RESULTADOS DEL GRID SEARCH\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\nMejores parámetros encontrados:\")\n",
        "print(grid_bosque.best_params_)\n",
        "print(f\"\\nMejor score (accuracy) con validación cruzada: {grid_bosque.best_score_:.4f}\")\n",
        "\n",
        "# Evaluar el mejor modelo en el conjunto de prueba\n",
        "mejor_bosque = grid_bosque.best_estimator_\n",
        "y_pred_optimizado = mejor_bosque.predict(X_test_ci)\n",
        "accuracy_optimizado = accuracy_score(y_test_ci, y_pred_optimizado)\n",
        "\n",
        "print(f\"\\nAccuracy en conjunto de prueba: {accuracy_optimizado:.4f}\")\n",
        "\n",
        "# Comparar con modelo sin optimizar\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"COMPARACIÓN: Sin Optimizar vs Optimizado\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Bosque sin optimizar (200 árboles, parámetros por defecto):\")\n",
        "print(f\"  Accuracy en prueba: {df_resultados_ci.loc['Bosque (200 árboles)', 'acc_test']:.4f}\")\n",
        "print(f\"\\nBosque optimizado (Grid Search):\")\n",
        "print(f\"  Accuracy en prueba: {accuracy_optimizado:.4f}\")\n",
        "print(f\"  Mejora: {accuracy_optimizado - df_resultados_ci.loc['Bosque (200 árboles)', 'acc_test']:.4f}\")\n",
        "\n",
        "# Mostrar algunos de los mejores resultados\n",
        "print(\"\\nTop 5 combinaciones de parámetros:\")\n",
        "resultados_grid = pd.DataFrame(grid_bosque.cv_results_)\n",
        "top_5 = resultados_grid.nlargest(5, 'mean_test_score')[\n",
        "    ['param_n_estimators', 'param_max_depth', 'param_min_samples_split',\n",
        "     'param_min_samples_leaf', 'mean_test_score', 'std_test_score']\n",
        "]\n",
        "print(top_5.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Validación cruzada para evaluar robustez del modelo\n",
        "print(\"=\" * 70)\n",
        "print(\"VALIDACIÓN CRUZADA (5-FOLD)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Realizar validación cruzada con el mejor modelo\n",
        "cv_scores = cross_val_score(mejor_bosque, X_train_ci, y_train_ci, cv=5, scoring='accuracy')\n",
        "\n",
        "print(f\"Scores por fold: {cv_scores}\")\n",
        "print(f\"\\nScore promedio: {cv_scores.mean():.4f}\")\n",
        "print(f\"Desviación estándar: {cv_scores.std():.4f}\")\n",
        "print(f\"Rango: [{cv_scores.min():.4f}, {cv_scores.max():.4f}]\")\n",
        "\n",
        "# Visualizar resultados de validación cruzada\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(range(1, 6), cv_scores, alpha=0.7, color='steelblue', edgecolor='black')\n",
        "plt.axhline(y=cv_scores.mean(), color='red', linestyle='--',\n",
        "           linewidth=2, label=f'Promedio: {cv_scores.mean():.4f}')\n",
        "plt.fill_between(range(1, 7),\n",
        "                 cv_scores.mean() - cv_scores.std(),\n",
        "                 cv_scores.mean() + cv_scores.std(),\n",
        "                 alpha=0.2, color='red', label=f'±1 desviación estándar')\n",
        "plt.xlabel('Fold')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Validación Cruzada 5-Fold - Bosque Aleatorio Optimizado')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3, axis='y')\n",
        "plt.xticks(range(1, 6))\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"metricas\"></a>\n",
        "## 9. Métricas de Evaluación para Clasificación [⬆](#introduccion)\n",
        "\n",
        "### 9.1 Matriz de Confusión\n",
        "\n",
        "La matriz de confusión muestra cuántas muestras fueron clasificadas correctamente y dónde se cometieron errores.\n",
        "\n",
        "#### Para Clasificación Multiclase (3 clases):\n",
        "| Real \\ Predicho | Funcional            | Marginal             | Fallado              |\n",
        "|-----------------|----------------------|----------------------|----------------------|\n",
        "| **Funcional**   | $\\textsf{TP}_1$      | $\\textsf{FN}_1→{}_2$ | $\\textsf{FN}_1→{}_3$ |\n",
        "| **Marginal**    | $\\textsf{FN}_2→{}_1$ | $\\textsf{TP}_2$      | $\\textsf{FN}_2→{}_3$ |\n",
        "| **Fallado**     | $\\textsf{FN}_3→{}_1$ | $\\textsf{FN}_3→{}_2$ | $\\textsf{TP}_3$      |\n",
        "\n",
        "Donde:\n",
        "- **TP** (True Positive): Correctamente identificado como esa clase\n",
        "- **FN** (False Negative): Clase A clasificada incorrectamente como clase B\n",
        "\n",
        "### 9.2 Métricas Principales\n",
        "\n",
        "#### Accuracy (Precisión Global)\n",
        "- **Fórmula**: $(\\textsf{TP}_1 + \\textsf{TP}_2 + \\textsf{TP}_3) / \\textsf{Total}$\n",
        "- **Interpretación**: Porcentaje de clasificaciones correctas\n",
        "- **Cuándo usar**: Clases balanceadas\n",
        "\n",
        "#### Precision por Clase\n",
        "- **Fórmula**: $\\textsf{Precision}_i = \\textsf{TP}_i / (\\textsf{TP}_i + \\textsf{FP}_i)$\n",
        "- **Interpretación**: De los predichos como clase $i$, ¿cuántos realmente son clase $i$?\n",
        "\n",
        "#### Recall por Clase (Sensibilidad)\n",
        "- **Fórmula**: $\\textsf{Recall}_i = \\textsf{TP}_i / (\\textsf{TP}_i + \\textsf{FN}_i)$\n",
        "- **Interpretación**: De los realmente clase $i$, ¿cuántos detectamos?\n",
        "\n",
        "#### F1-Score por Clase\n",
        "- **Fórmula**: $\\textsf{F1}_i = 2 \\times (\\textsf{Precision}_i \\times \\textsf{Recall}_i) / (\\textsf{Precision}_i + \\textsf{Recall}_i)$\n",
        "- **Interpretación**: Balance entre Precision y Recall (media armónica)\n",
        "\n",
        "#### F1-Score Macro (Promedio)\n",
        "- **Fórmula**: $\\textsf{F1}_\\textsf{macro} = \\frac{1}{n} \\sum_{i=1}^{n} \\textsf{F1}_i$\n",
        "- **Interpretación**: Promedio del F1 de todas las clases (sin considerar desbalance)\n",
        "\n",
        "### 9.3 ¿Qué Métrica Elegir?\n",
        "\n",
        "| Escenario                  | Métrica Principal  | Razón                                    |\n",
        "|----------------------------|--------------------|------------------------------------------|\n",
        "| Clases balanceadas         | **Accuracy**       | Representa bien el rendimiento           |\n",
        "| Clases desbalanceadas      | **F1-Score Macro** | No se sesga por clase mayoritaria        |\n",
        "| Clase crítica (ej: fallos) | **Recall**         | Detectar todos los casos                 |\n",
        "| Evitar falsos positivos    | **Precision**      | Asegurar que predicciones sean correctas |\n",
        "| Balance general            | **F1-Score**       | Equilibrio entre Precision y Recall      |\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"comparacion\"></a>\n",
        "## 10. Comparación con Otros Algoritmos [⬆](#introduccion)\n",
        "\n",
        "### Tabla Comparativa\n",
        "\n",
        "| Algoritmo               | Interpretabilidad | Velocidad Entrenamiento | Manejo No Lineal | Robustez | Sobreajuste |\n",
        "|-------------------------|-------------------|-------------------------|------------------|----------|-------------|\n",
        "| **Árbol Decisión**      | Muy Alta          | Muy Alta                | Alta             | Media    | Alto        |\n",
        "| **Random Forest**       | Alta              | Alta                    | Muy Alta         | Muy Alta | Bajo        |\n",
        "| **SVM**                 | Media             | Alta                    | Muy Alta         | Alta     | Medio       |\n",
        "| **Regresión Logística** | Muy Alta          | Muy Alta                | Baja             | Alta     | Bajo        |\n",
        "| **K-NN**                | Alta              | Muy Alta                | Muy Alta         | Baja     | Alto        |\n",
        "| **Redes Neuronales**    | Muy Baja          | Alta                    | Muy Alta         | Alta     | Alto        |\n",
        "\n",
        "### Cuándo Usar Cada Algoritmo\n",
        "\n",
        "#### Árbol de Decisión\n",
        "- Necesitas explicabilidad y reglas claras  \n",
        "- Dataset pequeño a mediano  \n",
        "- Quieres identificar variables importantes  \n",
        "- Necesitas modelo simple y rápido  \n",
        "\n",
        "#### Random Forest\n",
        "- Necesitas mejor precisión que árbol individual  \n",
        "- Dataset mediano a grande  \n",
        "- Relaciones no lineales complejas  \n",
        "- Poder computacional disponible  \n",
        "- Balance entre precisión e interpretabilidad  \n",
        "\n",
        "#### SVM\n",
        "- Dataset pequeño a mediano  \n",
        "- Separaciones no lineales complejas  \n",
        "- Alta dimensionalidad  \n",
        "\n",
        "#### Regresión Logística\n",
        "- Interpretabilidad importante  \n",
        "- Dataset grande  \n",
        "- Relaciones lineales o aproximadamente lineales  \n",
        "\n",
        "#### K-NN\n",
        "- Dataset pequeño  \n",
        "- Necesitas modelo simple  \n",
        "- Datos localmente estructurados  \n",
        "\n",
        "#### Redes Neuronales\n",
        "- Dataset muy grande  \n",
        "- Relaciones muy complejas  \n",
        "- Interpretabilidad no es crítica  \n",
        "\n",
        "---\n",
        "\n",
        "## 11. Ventajas y Desventajas - Resumen\n",
        "\n",
        "### Árboles de Decisión\n",
        "\n",
        "#### Ventajas\n",
        "- Altamente interpretable\n",
        "- No requiere normalización\n",
        "- Maneja datos no lineales\n",
        "- Identifica variables importantes\n",
        "- Rápido de entrenar\n",
        "\n",
        "#### Desventajas\n",
        "- Propenso a sobreajuste\n",
        "- Inestable (pequeños cambios cambian el árbol)\n",
        "- Sesgo hacia variables con más valores\n",
        "\n",
        "### Random Forest\n",
        "\n",
        "#### Ventajas\n",
        "- Mejor precisión que árbol individual\n",
        "- Menos sobreajuste\n",
        "- Robusto a outliers\n",
        "- Mide importancia de características\n",
        "- Maneja datos desbalanceados\n",
        "\n",
        "#### Desventajas\n",
        "- Menos interpretable que árbol individual\n",
        "- Más lento y uso de memoria\n",
        "- Parámetros adicionales a optimizar\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"resumen\"></a>\n",
        "## 12. Resumen y Conclusiones [⬆](#introduccion)\n",
        "\n",
        "### 12.1 Puntos Clave para Recordar\n",
        "\n",
        "#### Los 3 Conceptos Esenciales de Árboles\n",
        "1. **Impureza (Gini/Entropía)**: Mide mezcla de clases en un nodo\n",
        "2. **Ganancia de Información**: Guía qué atributo usar para dividir\n",
        "3. **Poda**: Previene sobreajuste limitando complejidad\n",
        "\n",
        "#### Los 3 Conceptos Esenciales de Random Forest\n",
        "1. **Bootstrap Aggregating**: Cada árbol ve datos diferentes\n",
        "2. **Selección Aleatoria de Características**: Reduce correlación entre árboles\n",
        "3. **Votación Mayoritaria**: Decisión final por consenso\n",
        "\n",
        "#### Los 3 Parámetros Críticos\n",
        "1. **max_depth**: Controla profundidad (complejidad)\n",
        "2. **n_estimators**: Número de árboles en el bosque\n",
        "3. **min_samples_split**: Controla cuándo dividir un nodo\n",
        "\n",
        "### 12.2 Flujo de Trabajo Recomendado\n",
        "\n",
        "1. **Explorar datos**\n",
        "   - Visualizar distribuciones\n",
        "   - Analizar correlaciones\n",
        "   - Entender desbalance de clases\n",
        "\n",
        "2. **Árbol de decisión simple**\n",
        "   - Entrenar árbol básico como baseline\n",
        "   - Visualizar reglas\n",
        "   - Analizar sobreajuste\n",
        "\n",
        "3. **Random Forest**\n",
        "   - Entrenar bosque con parámetros razonables\n",
        "   - Analizar importancia de características\n",
        "   - Comparar con árbol individual\n",
        "\n",
        "4. **Optimización**\n",
        "   - Grid Search con validación cruzada\n",
        "   - Evaluar robustez\n",
        "   - Seleccionar mejor modelo\n",
        "\n",
        "5. **Evaluación final**\n",
        "   - Matriz de confusión\n",
        "   - Métricas apropiadas (Accuracy, F1, etc.)\n",
        "   - Interpretar resultados\n",
        "\n",
        "### 12.3 Mejores Prácticas\n",
        "\n",
        "#### Hacer SIEMPRE\n",
        "1. **Dividir datos** en entrenamiento y prueba (stratify si clases desbalanceadas)\n",
        "2. **Visualizar árboles** para entender decisiones (profundidad limitada)\n",
        "3. **Comprobar sobreajuste** comparando train vs test accuracy\n",
        "4. **Usar Grid Search** con validación cruzada para optimizar\n",
        "5. **Analizar importancia** de características\n",
        "6. **Usar métricas apropiadas** según el problema (F1 para clases desbalanceadas)\n",
        "\n",
        "#### Errores Comunes a Evitar\n",
        "1. **No limitar profundidad** → Sobreajuste garantizado\n",
        "2. **Usar datos de prueba durante entrenamiento** → Estimación sesgada\n",
        "3. **Ignorar desbalance de clases** → Modelo sesgado hacia clase mayoritaria\n",
        "4. **No validar con cross-validation** → Estimación no robusta\n",
        "5. **Confiar solo en Accuracy** → Puede engañar con clases desbalanceadas\n",
        "\n",
        "### 12.4 Aplicaciones en Ingeniería Electrónica\n",
        "\n",
        "#### Casos de Uso Reales\n",
        "1. **Control de Calidad**\n",
        "   - Clasificación de componentes funcionales/fallados\n",
        "   - Detección de defectos en fabricación\n",
        "\n",
        "2. **Detección de Fallas**\n",
        "   - Diagnóstico de circuitos\n",
        "   - Predicción de fallas anticipadas\n",
        "\n",
        "3. **Monitoreo de Procesos**\n",
        "   - Clasificación de estados de operación\n",
        "   - Detección de anomalías\n",
        "\n",
        "4. **Calibración Automatizada**\n",
        "   - Clasificación de niveles de ajuste necesarios\n",
        "   - Selección de parámetros óptimos\n",
        "\n",
        "### 12.5 Próximos Pasos\n",
        "\n",
        "#### Para Practicar\n",
        "1. Aplicar a dataset real de tu área\n",
        "2. Experimentar con diferentes parámetros\n",
        "3. Comparar con otros algoritmos (SVM, K-NN)\n",
        "4. Implementar en casos industriales reales\n",
        "\n",
        "#### Para Profundizar\n",
        "- **Gradient Boosting**: XGBoost, LightGBM (ensembles avanzados)\n",
        "- **Análisis de importancia**: SHAP values para explicabilidad\n",
        "- **Árboles de regresión**: Aplicar conceptos a problemas continuos\n",
        "- **Optimización bayesiana**: Alternativa más eficiente a Grid Search\n",
        "\n",
        "---\n",
        "\n",
        "## 13. Recursos y Referencias\n",
        "\n",
        "### Documentación\n",
        "- [Scikit-learn: Decision Trees](https://scikit-learn.org/stable/modules/tree.html)\n",
        "- [Scikit-learn: Random Forest](https://scikit-learn.org/stable/modules/ensemble.html#random-forests)\n",
        "- [Grid Search Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
        "\n",
        "### Libros Recomendados\n",
        "- \"An Introduction to Statistical Learning\" - James, Witten, Hastie, Tibshirani\n",
        "- \"Pattern Recognition and Machine Learning\" - Christopher Bishop\n",
        "- \"The Elements of Statistical Learning\" - Hastie, Tibshirani, Friedman\n",
        "\n",
        "### Cursos Online\n",
        "- Machine Learning por Andrew Ng (Coursera)\n",
        "- Applied Machine Learning (edX)\n",
        "\n",
        "---\n",
        "\n",
        "## 14. Apéndice: Ejemplo de Interpretación de Reglas\n",
        "\n",
        "### Reglas de Decisión Ejemplo\n",
        "```txt\n",
        "SI temperatura <= 50°C:\n",
        "    SI voltaje <= 5.2V:\n",
        "        → Componente FUNCIONAL (95% confianza)\n",
        "    SINO:\n",
        "        SI corriente <= 110mA:\n",
        "            → Componente DEGRADADO (78% confianza)\n",
        "        SINO:\n",
        "            → Componente CON FALLA (82% confianza)\n",
        "SINO:\n",
        "    SI temperatura <= 75°C:\n",
        "        → Componente DEGRADADO (85% confianza)\n",
        "    SINO:\n",
        "        → Componente CON FALLA (92% confianza)\n",
        "```\n",
        "\n",
        "### Interpretación\n",
        "- **Primera pregunta**: Temperatura es la variable más importante\n",
        "- **Valores de umbral**: 50°C y 75°C son puntos críticos\n",
        "- **Confianza**: Probabilidad de clasificación correcta\n",
        "\n",
        "---\n",
        "\n",
        "## ¿Preguntas?\n",
        "\n",
        "*Tiempo restante para preguntas y discusión*\n",
        "\n",
        "---\n",
        "\n",
        "## ¡Gracias por su atención!\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
